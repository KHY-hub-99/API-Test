# Seoul Dual Congestion Prediction Model (Traffic & Crowd)
# Features: Traffic, Floating Population, Day of Week, Holidays, Weather, Road Capacity

import pandas as pd
import numpy as np
import requests
import xml.etree.ElementTree as ET
from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from datetime import datetime
import glob
import os
import dotenv
import time
import joblib

dotenv.load_dotenv()

np.random.seed(42)

# ============================================
# CONFIGURATION
# ============================================
SDOT_API_KEY = os.getenv("SDOT_API_KEY")
SDOT_API_URL = f"http://openapi.seoul.go.kr:8088/{SDOT_API_KEY}/xml/IotVdata018"
TRAFFIC_DATA_PATH = "./data"

# ============================================
# REAL-TIME WEATHER FUNCTION
# ============================================
def get_current_weather_seoul():
    """Fetch current weather for Seoul from wttr.in (free, no API key needed)"""
    try:
        url = "https://wttr.in/Seoul?format=j1"
        response = requests.get(url, timeout=10)
        response.raise_for_status()

        weather_data = response.json()
        current = weather_data['current_condition'][0]

        temp = int(current['temp_C'])
        humidity = int(current['humidity'])
        weather_desc = current['weatherDesc'][0]['value'].lower()

        rain_keywords = ['rain', 'drizzle', 'shower', 'thunderstorm', 'sleet']
        is_raining = any(keyword in weather_desc for keyword in rain_keywords)

        snow_keywords = ['snow', 'blizzard', 'ice']
        is_snowing = any(keyword in weather_desc for keyword in snow_keywords)

        return {
            'temp': temp,
            'humidity': humidity,
            'description': weather_desc,
            'is_raining': is_raining,
            'is_snowing': is_snowing,
            'success': True
        }
    except Exception as e:
        return {
            'temp': None, 'humidity': None, 'description': 'unknown',
            'is_raining': False, 'is_snowing': False, 'success': False, 'error': str(e)
        }

# ============================================
# KOREAN HOLIDAYS 2025 (ê³µíœ´ì¼)
# ============================================
KOREAN_HOLIDAYS_2025 = {
    '20250101': 'ì‹ ì •', '20250128': 'ì„¤ë‚ ì—°íœ´', '20250129': 'ì„¤ë‚ ', '20250130': 'ì„¤ë‚ ì—°íœ´',
    '20250301': 'ì‚¼ì¼ì ˆ', '20250303': 'ëŒ€ì²´ê³µíœ´ì¼', '20250505': 'ì–´ë¦°ì´ë‚ ',
    '20250506': 'ëŒ€ì²´ê³µíœ´ì¼', '20250606': 'í˜„ì¶©ì¼', '20250815': 'ê´‘ë³µì ˆ',
    '20251003': 'ê°œì²œì ˆ', '20251005': 'ì¶”ì„ì—°íœ´', '20251006': 'ì¶”ì„',
    '20251007': 'ì¶”ì„ì—°íœ´', '20251008': 'ëŒ€ì²´ê³µíœ´ì¼', '20251009': 'í•œê¸€ë‚ ',
    '20251225': 'í¬ë¦¬ìŠ¤ë§ˆìŠ¤'
}

# ============================================
# ROAD CAPACITY DATA (ë„ë¡œ ìš©ëŸ‰)
# ============================================
ROAD_CAPACITY = {
    'í„°ë„': 2500, 'ëŒ€ë¡œ': 2000, 'ë¡œ': 1500, 'ì—­': 1800, 'default': 1600
}

# ============================================
# WEATHER PATTERNS FOR SEOUL 2025
# ============================================
SEOUL_WEATHER_2025 = {
    1: {'temp': -2, 'rain_prob': 15}, 2: {'temp': 1, 'rain_prob': 15},
    3: {'temp': 6, 'rain_prob': 25}, 4: {'temp': 13, 'rain_prob': 30},
    5: {'temp': 18, 'rain_prob': 35}, 6: {'temp': 23, 'rain_prob': 50},
    7: {'temp': 26, 'rain_prob': 60}, 8: {'temp': 27, 'rain_prob': 45},
    9: {'temp': 22, 'rain_prob': 35}, 10: {'temp': 15, 'rain_prob': 25},
    11: {'temp': 7, 'rain_prob': 20}, 12: {'temp': 0, 'rain_prob': 20}
}

WEATHER_IMPACT = {
    'clear': 1.0, 'cloudy': 1.05, 'rain': 1.3,
    'heavy_rain': 1.5, 'snow': 1.4, 'cold': 1.1, 'hot': 1.1
}

# ============================================
# STEP 1: Load Traffic Volume Data from Excel
# ============================================
def load_traffic_data():
    print("=== Loading Traffic Volume Data (êµí†µëŸ‰ ë°ì´í„° ë¡œë”©) ===")
    excel_files = glob.glob(os.path.join(TRAFFIC_DATA_PATH, "*.xlsx"))
    all_traffic_data = []

    for file in sorted(excel_files):
        print(f"  Loading: {os.path.basename(file)}")
        xlsx = pd.ExcelFile(file)
        data_sheets = [s for s in xlsx.sheet_names if "2025ë…„" in s]
        if data_sheets:
            df = pd.read_excel(xlsx, sheet_name=data_sheets[0])
            all_traffic_data.append(df)

    if all_traffic_data:
        traffic_df = pd.concat(all_traffic_data, ignore_index=True)
        print(f"\nTotal traffic records loaded: {len(traffic_df):,}")
        return traffic_df
    return None

# ============================================
# STEP 2: Fetch Floating Population from S-DoT API
# ============================================
def fetch_floating_population(start=1, end=5000):
    print(f"\n=== Fetching Floating Population Data (ìœ ë™ì¸êµ¬ ë°ì´í„° ìˆ˜ì§‘) ===")
    print(f"  Target Range: {start} to {end}")
    
    all_data = []
    current_start = start
    batch_size = 1000  

    while current_start <= end:
        current_end = min(current_start + batch_size - 1, end)
        print(f"  Requesting batch: {current_start} ~ {current_end}...")
        
        url = f"{SDOT_API_URL}/{current_start}/{current_end}/"

        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            root = ET.fromstring(response.content)
            
            result_code = root.find('.//CODE')
            if result_code is not None and result_code.text != 'INFO-000':
                print(f"  API Warning at batch {current_start}: {result_code.text}")
                break

            rows = root.findall('.//row')
            if not rows: break

            for row in rows:
                all_data.append({
                    'sensing_time': row.findtext('SENSING_TIME'),
                    'region': row.findtext('REGION'),
                    'visitor_count': int(row.findtext('VISITOR_COUNT') or 0),
                })
            
            current_start += batch_size
            time.sleep(0.1) 

        except Exception as e:
            print(f"  API request failed at {current_start}: {e}")
            break

    if all_data:
        df = pd.DataFrame(all_data)
        print(f"  âœ… Successfully fetched {len(df)} total records.")
        return df
    else:
        print("  âŒ Failed to fetch any data.")
        return None

# ============================================
# STEP 3: Feature Engineering Functions
# ============================================
def get_day_of_week(date_str):
    try: return datetime.strptime(str(date_str), '%Y%m%d').weekday()
    except: return 0

def get_day_name_korean(day_str):
    """ 'ì›”' -> 0, 'í™”' -> 1 ë¡œ ë³€í™˜ """
    day_map = {'ì›”': 0, 'í™”': 1, 'ìˆ˜': 2, 'ëª©': 3, 'ê¸ˆ': 4, 'í† ': 5, 'ì¼': 6}
    try: return day_map.get(str(day_str).strip(), 0)
    except: return 0

def is_weekend(day_of_week): return 1 if day_of_week >= 5 else 0
def is_holiday(date_str): return 1 if str(date_str) in KOREAN_HOLIDAYS_2025 else 0
def get_month(date_str):
    try: return int(str(date_str)[4:6])
    except: return 1

def get_road_capacity(location_name):
    location_name = str(location_name)
    if 'í„°ë„' in location_name: return ROAD_CAPACITY['í„°ë„']
    elif 'ëŒ€ë¡œ' in location_name: return ROAD_CAPACITY['ëŒ€ë¡œ']
    elif 'ì—­' in location_name: return ROAD_CAPACITY['ì—­']
    elif 'ë¡œ' in location_name: return ROAD_CAPACITY['ë¡œ']
    else: return ROAD_CAPACITY['default']

def get_weather_features(month, hour):
    weather = SEOUL_WEATHER_2025.get(month, SEOUL_WEATHER_2025[1])
    np.random.seed(month * 100 + hour)
    rain_prob = weather['rain_prob']
    if 14 <= hour <= 18: rain_prob *= 1.2
    
    is_raining = 1 if np.random.random() < (rain_prob / 100) else 0
    impact = WEATHER_IMPACT['clear']
    
    if is_raining:
        impact = WEATHER_IMPACT['heavy_rain'] if rain_prob > 50 else WEATHER_IMPACT['rain']
    elif weather['temp'] < 0: impact = WEATHER_IMPACT['cold']
    elif weather['temp'] > 30: impact = WEATHER_IMPACT['hot']

    return {
        'temperature': weather['temp'], 'rain_prob': rain_prob,
        'is_raining': is_raining, 'weather_impact': impact
    }

# ============================================
# STEP 4: Process and Prepare Training Data (ê³ ì† ìµœì í™”)
# ============================================
def prepare_training_data(traffic_df, population_df=None):
    print("\n=== Preparing Training Data (í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ - ê³ ì† ìµœì í™” ë²„ì „) ===")

    # 1. êµí†µ ë°ì´í„° ì „ì²˜ë¦¬
    print("  1. Transforming traffic data (Melting)...")
    hour_cols = [f"{i}ì‹œ" for i in range(24)]
    available_hour_cols = [col for col in hour_cols if col in traffic_df.columns]
    
    traffic_long = traffic_df.melt(
        id_vars=['ì¼ì', 'ìš”ì¼', 'ì§€ì ëª…'], 
        value_vars=available_hour_cols,
        var_name='ì‹œê°„', value_name='traffic_volume'
    ).dropna()
    
    traffic_long['hour'] = traffic_long['ì‹œê°„'].str.replace('ì‹œ', '').astype(int)
    print(f"     -> Rows to process: {len(traffic_long):,}")

    # 2. ê¸°ë³¸ íŠ¹ì„± ì¶”ê°€
    print("  2. Adding basic features...")
    day_map = {'ì›”': 0, 'í™”': 1, 'ìˆ˜': 2, 'ëª©': 3, 'ê¸ˆ': 4, 'í† ': 5, 'ì¼': 6}
    traffic_long['day_of_week'] = traffic_long['ìš”ì¼'].map(lambda x: day_map.get(str(x).strip(), 0))
    
    traffic_long['is_weekend'] = traffic_long['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)
    traffic_long['is_holiday'] = traffic_long['ì¼ì'].apply(is_holiday)
    traffic_long['month'] = traffic_long['ì¼ì'].astype(str).str[4:6].astype(int)
    
    # ë„ë¡œ ìš©ëŸ‰ ë§¤í•‘
    print("  3. Mapping road capacity...")
    def fast_capacity(name):
        if 'í„°ë„' in name: return 2500
        if 'ëŒ€ë¡œ' in name: return 2000
        if 'ì—­' in name: return 1800
        if 'ë¡œ' in name: return 1500
        return 1600
    traffic_long['road_capacity'] = traffic_long['ì§€ì ëª…'].apply(fast_capacity)
    
    # 3. ë‚ ì”¨ íŠ¹ì„± ì¶”ê°€ (Lookup Table ë°©ì‹)
    print("  4. Calculating weather features (Optimized)...")
    weather_lookup = []
    for m in range(1, 13):
        for h in range(24):
            w = get_weather_features(m, h)
            w['month'] = m
            w['hour'] = h
            weather_lookup.append(w)
    
    weather_df = pd.DataFrame(weather_lookup)
    traffic_long = traffic_long.merge(weather_df, on=['month', 'hour'], how='left')

    # 4. ë°ì´í„° ì§‘ê³„
    print("  5. Aggregating data...")
    group_cols = ['ì§€ì ëª…', 'hour', 'day_of_week', 'month', 'is_weekend', 'is_holiday', 'road_capacity']
    mean_cols = ['traffic_volume', 'temperature', 'rain_prob', 'weather_impact']
    aggregated = traffic_long.groupby(group_cols)[mean_cols].mean().reset_index()

    # 5. ìœ ë™ì¸êµ¬ ë³‘í•©
    print("  6. Merging floating population...")
    if population_df is not None and not population_df.empty:
        population_df['sensing_str'] = population_df['sensing_time'].astype(str)
        population_df['hour'] = population_df['sensing_str'].str.extract(r'_(\d{2}):').astype(float).fillna(0).astype(int)
        
        pop_agg = population_df.groupby('hour')['visitor_count'].mean().reset_index()
        pop_agg['floating_population'] = (pop_agg['visitor_count'] * 100).astype(int)
        aggregated = aggregated.merge(pop_agg, on='hour', how='left')
        aggregated['floating_population'] = aggregated['floating_population'].ffill().fillna(30000)
    else:
        aggregated['floating_population'] = np.random.randint(5000, 100000, size=len(aggregated))

    # 6. Location Encoding
    locations = aggregated['ì§€ì ëª…'].unique()
    location_to_num = {loc: i for i, loc in enumerate(locations)}
    aggregated['location_code'] = aggregated['ì§€ì ëª…'].map(location_to_num)

    # 7. ì •ë‹µ(Label) ìƒì„±
    print("  7. Generating labels...")
    aggregated['capacity_ratio'] = aggregated['traffic_volume'] / aggregated['road_capacity']
    
    thresholds = 0.85 / aggregated['weather_impact']
    conditions = [
        (aggregated['capacity_ratio'] > thresholds),
        (aggregated['capacity_ratio'] > thresholds * 0.6)
    ]
    choices = [2, 1] 
    aggregated['traffic_level'] = np.select(conditions, choices, default=0)

    max_pop_df = aggregated.groupby('ì§€ì ëª…')['floating_population'].max().reset_index()
    max_pop_df.columns = ['ì§€ì ëª…', 'max_pop']
    aggregated = aggregated.merge(max_pop_df, on='ì§€ì ëª…', how='left')
    aggregated['pop_ratio'] = aggregated['floating_population'] / aggregated['max_pop']
    
    pop_conditions = [
        (aggregated['pop_ratio'] > 0.8),
        (aggregated['pop_ratio'] > 0.5)
    ]
    aggregated['crowd_level'] = np.select(pop_conditions, [2, 1], default=0)

    print(f"  âœ… Dataset Ready: {len(aggregated)} rows processed.")
    return aggregated, location_to_num, locations

# ============================================
# STEP 5: Train Model (ìˆ˜ì •ë¨ - Train/Test ë¶„ë¦¬ ë° ìƒì„¸ í‰ê°€)
# ============================================
def train_model(data):
    print("\n=== Training Dual Models (Gradient Boosting: ì„±ëŠ¥ ê°œì„  ë²„ì „) ===")

    feature_cols = [
        'location_code', 'hour', 'day_of_week', 'month', 
        'is_weekend', 'is_holiday', 
        'temperature', 'rain_prob', 'weather_impact', 'road_capacity'
    ]
    
    X = data[feature_cols]
    y_traffic = data['traffic_level'] 
    y_crowd = data['crowd_level']     

    # ë°ì´í„° ë¶„ë¦¬
    X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(
        X, y_traffic, test_size=0.2, random_state=42, stratify=y_traffic
    )
    X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(
        X, y_crowd, test_size=0.2, random_state=42, stratify=y_crowd
    )

    print(f"  ğŸ“Š Data Split: Train {len(X_train_t):,} / Test {len(X_test_t):,}")

    # ==========================================
    # 3. ëª¨ë¸ 1: êµí†µ í˜¼ì¡ë„ (ë¶€ìŠ¤íŒ… ëª¨ë¸ ì ìš©)
    # ==========================================
    print("\n  ğŸš— [1] Training Traffic Model (Gradient Boosting)...")
    
    # [í•µì‹¬ ë³€ê²½] RandomForest -> HistGradientBoostingClassifier
    # ì´ ëª¨ë¸ì€ í‹€ë¦° ë¬¸ì œë¥¼ ì§‘ì¤‘ì ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.
    model_traffic = HistGradientBoostingClassifier(
        max_iter=500,            # í•™ìŠµ íšŸìˆ˜ë¥¼ ëŒ€í­ ëŠ˜ë¦¼ (ê¸°ì¡´ 200 -> 500)
        learning_rate=0.05,      # [ì¤‘ìš”] íšŸìˆ˜ê°€ ëŠ˜ì–´ë‚œ ë§Œí¼ í•™ìŠµ ì†ë„ë¥¼ ëŠ¦ì¶¤ (ê¸°ì¡´ 0.1 -> 0.05)
        max_depth=12,            # ë‚˜ë¬´ ê¹Šì´ë¥¼ ì œí•œí•˜ì—¬ ê³¼ì í•© ë°©ì§€
        min_samples_leaf=40,     # í•œ ë…¸ë“œì— ìµœì†Œ 40ê°œì˜ ë°ì´í„°ê°€ ìˆì–´ì•¼ ë¶„ê¸° (ë…¸ì´ì¦ˆ ë¬´ì‹œ)
        l2_regularization=1.5,   # ê·œì œ ê°•ë„ ì¦ê°€ (ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ)
        early_stopping=True,     # [í•„ìˆ˜] ë” ì´ìƒ ì¢‹ì•„ì§€ì§€ ì•Šìœ¼ë©´ 500ë²ˆ ë‹¤ ì•ˆ ì±„ìš°ê³  ë©ˆì¶¤ (ì‹œê°„ ì ˆì•½)
        random_state=42,
        class_weight='balanced'  # ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œ
    )
    model_traffic.fit(X_train_t, y_train_t)
    
    y_pred_t = model_traffic.predict(X_test_t)
    acc_t = accuracy_score(y_test_t, y_pred_t)
    
    print(f"    ğŸ‘‰ Accuracy: {acc_t*100:.1f}%")
    print("    ğŸ‘‰ Classification Report:")
    print(classification_report(y_test_t, y_pred_t, target_names=['Low', 'Medium', 'High']))

    # ==========================================
    # 4. ëª¨ë¸ 2: ì¸êµ¬ í˜¼ì¡ë„
    # ==========================================
    print("\n  ğŸ‘¥ [2] Training Crowd Model (Gradient Boosting)...")
    model_crowd = HistGradientBoostingClassifier(
        max_iter=500,            # í•™ìŠµ íšŸìˆ˜ë¥¼ ëŒ€í­ ëŠ˜ë¦¼ (ê¸°ì¡´ 200 -> 500)
        learning_rate=0.05,      # [ì¤‘ìš”] íšŸìˆ˜ê°€ ëŠ˜ì–´ë‚œ ë§Œí¼ í•™ìŠµ ì†ë„ë¥¼ ëŠ¦ì¶¤ (ê¸°ì¡´ 0.1 -> 0.05)
        max_depth=12,            # ë‚˜ë¬´ ê¹Šì´ë¥¼ ì œí•œí•˜ì—¬ ê³¼ì í•© ë°©ì§€
        min_samples_leaf=40,     # í•œ ë…¸ë“œì— ìµœì†Œ 40ê°œì˜ ë°ì´í„°ê°€ ìˆì–´ì•¼ ë¶„ê¸° (ë…¸ì´ì¦ˆ ë¬´ì‹œ)
        l2_regularization=1.5,   # ê·œì œ ê°•ë„ ì¦ê°€ (ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ)
        early_stopping=True,     # [í•„ìˆ˜] ë” ì´ìƒ ì¢‹ì•„ì§€ì§€ ì•Šìœ¼ë©´ 500ë²ˆ ë‹¤ ì•ˆ ì±„ìš°ê³  ë©ˆì¶¤ (ì‹œê°„ ì ˆì•½)
        random_state=42,
        class_weight='balanced'  # ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œ
    )
    model_crowd.fit(X_train_c, y_train_c)
    
    y_pred_c = model_crowd.predict(X_test_c)
    acc_c = accuracy_score(y_test_c, y_pred_c)
    
    print(f"    ğŸ‘‰ Accuracy: {acc_c*100:.1f}%")
    print("    ğŸ‘‰ Classification Report:")
    print(classification_report(y_test_c, y_pred_c, target_names=['Low', 'Medium', 'High']))

    # (ì°¸ê³ ) HistGradientBoostingì€ feature_importances_ ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤.
    # ëŒ€ì‹  permutation importanceë¥¼ ì¨ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ìƒëµí•˜ê³  ì»¬ëŸ¼ ëª©ë¡ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    return model_traffic, model_crowd, feature_cols

def save_models(model_t, model_c, loc_map, features, filepath="seoul_congestion_model.pkl"):
    # [NEW] model í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
    directory = os.path.dirname(filepath)
    if directory and not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)
        print(f"ğŸ“‚ Created directory: {directory}")

    print(f"\nğŸ’¾ Saving models to {filepath}...")
    package = {
        'traffic_model': model_t,
        'crowd_model': model_c,
        'location_map': loc_map,
        'features': features,
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    joblib.dump(package, filepath)
    print("  âœ… Save complete!")

def load_models(filepath="seoul_congestion_model.pkl"):
    """ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not os.path.exists(filepath):
        return None
    
    print(f"\nğŸ“‚ Loading models from {filepath}...")
    try:
        package = joblib.load(filepath)
        print(f"  âœ… Load complete! (Saved at: {package.get('timestamp', 'Unknown')})")
        return package
    except Exception as e:
        print(f"  âŒ Error loading file: {e}")
        return None

# ============================================
# STEP 6: Make Predictions
# ============================================
def predict_congestion(model_traffic, model_crowd, feature_cols, location_to_num, 
                       location_name, hour, day_of_week, month, is_weekend, is_holiday, 
                       road_cap, temp, rain_prob, weather_impact):
    
    if location_name not in location_to_num:
        return None, None

    input_data = pd.DataFrame([{
        'location_code': location_to_num[location_name],
        'hour': hour,
        'day_of_week': day_of_week,
        'month': month,
        'is_weekend': is_weekend,
        'is_holiday': is_holiday,
        'temperature': temp,
        'rain_prob': rain_prob,
        'weather_impact': weather_impact,
        'road_capacity': road_cap
    }])

    t_pred = model_traffic.predict(input_data)[0]
    c_pred = model_crowd.predict(input_data)[0]

    level_map = {0: "Low (ì¾Œì )", 1: "Medium (ë³´í†µ)", 2: "High (í˜¼ì¡)"}
    return level_map[t_pred], level_map[c_pred]

# ============================================
# MAIN EXECUTION
# ============================================
if __name__ == "__main__":
    print("=" * 70)
    print("Seoul Dual Congestion Prediction Model")
    print("=" * 70)

    # [ìˆ˜ì •] ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ 'model' í´ë”ë¡œ ë³€ê²½
    model_file_path = "./model/seoul_congestion_model.pkl"
    
    # 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹œë„
    saved_package = load_models(model_file_path)

    if saved_package:
        # íŒŒì¼ì´ ìˆìœ¼ë©´ ë°”ë¡œ ë¡œë“œ
        model_t = saved_package['traffic_model']
        model_c = saved_package['crowd_model']
        location_to_num = saved_package['location_map']
        features = saved_package['features']
        locations = list(location_to_num.keys()) # ì¥ì†Œ ë¦¬ìŠ¤íŠ¸ ë³µì›
        
    else:
        # 2. íŒŒì¼ì´ ì—†ìœ¼ë©´ í•™ìŠµ ì‹œì‘
        print("ğŸš€ No saved model found. Starting training process...")
        
        # Step 1: ë°ì´í„° ë¡œë“œ
        traffic_df = load_traffic_data()
        if traffic_df is None: exit(1)

        # Step 2: ìœ ë™ì¸êµ¬ ë°ì´í„° í™•ì¸ (ì—¬ê¸°ëŠ” data í´ë” ìœ ì§€)
        data_dir = "./data"
        pop_file = os.path.join(data_dir, "floating_population.xlsx")
        
        if os.path.exists(pop_file):
            print(f"ğŸ“‚ Loading existing population data...")
            population_df = pd.read_excel(pop_file)
        else:
            population_df = fetch_floating_population(start=1, end=5000)
            if population_df is not None:
                os.makedirs(data_dir, exist_ok=True)
                population_df.to_excel(pop_file, index=False)

        # Step 3: ë°ì´í„° ì „ì²˜ë¦¬
        data, location_to_num, locations = prepare_training_data(traffic_df, population_df)

        # Step 4: í•™ìŠµ
        model_t, model_c, features = train_model(data)
        
        # Step 5: [ì¤‘ìš”] í•™ìŠµ í›„ 'model' í´ë”ì— ì €ì¥
        save_models(model_t, model_c, location_to_num, features, model_file_path)

    # ============================================
    # INTERACTIVE MODE
    # ============================================
    print("\n" + "=" * 70)
    print("INTERACTIVE MODE (ëŒ€í™”í˜• ì˜ˆì¸¡ ëª¨ë“œ)")
    print("=" * 70)
    print("âœ“ êµí†µ(Traffic)ê³¼ ì¸êµ¬(Crowd) í˜¼ì¡ë„ë¥¼ ê°ê° ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
    print("âœ“ ë¯¸ë˜ ì˜ˆì¸¡ ì‹œ êµí†µëŸ‰ì„ ì…ë ¥í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. (íŒ¨í„´ ê¸°ë°˜ ì˜ˆì¸¡)")
    print("\nEnter 'q' to quit (ì¢…ë£Œí•˜ë ¤ë©´ 'q' ì…ë ¥)\n")

    location_list = list(locations)
    for i, loc in enumerate(location_list[:10]): print(f"  {loc}")
    if len(location_list) > 10: print(f"  ... and {len(location_list) - 10} more")
    print("\n  ğŸ’¡ Tip: ê²€ìƒ‰í•  ì§€ì ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ê°•ë‚¨)")
    print()

    while True:
        try:
            print("-" * 50)
            now = datetime.now()
            day_names_en = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']

            # 1. ì¥ì†Œ ì„ íƒ
            loc_input = input("Location (ì§€ì ëª… ê²€ìƒ‰): ").strip()
            if loc_input.lower() == 'q': break
            if not loc_input: loc_input = location_list[0]

            matches = [loc for loc in location_list if loc_input.lower() in loc.lower()]
            if not matches:
                print(f"  âŒ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{loc_input}'")
                continue
            elif len(matches) == 1: selected_loc = matches[0]
            else:
                for i, loc in enumerate(matches[:10]): print(f"    {i}: {loc}")
                choice = input("  Select number [0]: ").strip()
                if choice.lower() == 'q': break
                choice_idx = int(choice) if choice else 0
                selected_loc = matches[choice_idx]

            road_cap = get_road_capacity(selected_loc)
            print(f"  âœ“ Selected: {selected_loc}")

            # 2. ì‹œê°„ ì„ íƒ
            time_choice = input(f"Use current time? ({now.hour}:00) [Y/n]: ").strip().lower()
            if time_choice == 'q': break

            if time_choice == 'n':
                month = int(input("Month (1-12): ").strip())
                day = int(input("Day (1-31): ").strip())
                hour = int(input("Hour (0-23): ").strip())
                
                sel_date = datetime(2025, month, day)
                dow = sel_date.weekday()
                date_str = f"2025{month:02d}{day:02d}"
                is_hol = 1 if date_str in KOREAN_HOLIDAYS_2025 else 0
                is_wknd = 1 if dow >= 5 else 0
            else:
                hour = now.hour
                dow = now.weekday()
                month = now.month
                today_str = now.strftime('%Y%m%d')
                is_hol = 1 if today_str in KOREAN_HOLIDAYS_2025 else 0
                is_wknd = 1 if dow >= 5 else 0

            # 3. ë‚ ì”¨ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            print("\n  ğŸŒ¤ï¸ ë‚ ì”¨ ì •ë³´ í™•ì¸ ì¤‘...")
            weather = get_current_weather_seoul()
            if weather['success']:
                temp = weather['temp']
                is_rain = 1 if weather['is_raining'] else 0
            else:
                temp = SEOUL_WEATHER_2025.get(month, {}).get('temp', 15)
                is_rain = 0
            
            w_impact = 1.3 if is_rain else 1.0
            rain_prob = 80 if is_rain else 10

            # 4. ì˜ˆì¸¡ ìˆ˜í–‰
            t_res, c_res = predict_congestion(
                model_t, model_c, features, location_to_num, selected_loc,
                hour, dow, month, is_wknd, is_hol,
                road_cap, temp, rain_prob, w_impact
            )

            # 5. ê²°ê³¼ ì¶œë ¥
            print("\n" + "="*50)
            print(f"ğŸ“ {selected_loc} ì˜ˆì¸¡ ë¦¬í¬íŠ¸")
            print(f"ğŸ“… {month}ì›” {day_names_en[dow]} {hour}ì‹œ | ğŸŒ¡ï¸ {temp}Â°C")
            print("-" * 50)
            
            icon_t = "ğŸŸ¢" if "Low" in t_res else ("ğŸ”´" if "High" in t_res else "ğŸŸ¡")
            print(f"ğŸš— [êµí†µ í˜¼ì¡ë„] : {icon_t} {t_res}")
            
            icon_c = "ğŸŸ¢" if "Low" in c_res else ("ğŸ”´" if "High" in c_res else "ğŸŸ¡")
            print(f"ğŸ‘¥ [ì¸êµ¬ í˜¼ì¡ë„] : {icon_c} {c_res}")
            
            if "High" in t_res and "High" in c_res:
                print("\nğŸš¨ ê²½ê³ : ìµœì•…ì˜ í˜¼ì¡ ì‹œê°„ëŒ€ì…ë‹ˆë‹¤! ìš°íšŒ ê¶Œì¥.")
            elif "High" in t_res:
                print("\nğŸ’¡ íŒ: ë„ë¡œëŠ” ë§‰íˆì§€ë§Œ ì‚¬ëŒì€ ì ìŠµë‹ˆë‹¤. ëŒ€ì¤‘êµí†µ ì´ìš© ì¶”ì²œ!")
            elif "High" in c_res:
                print("\nğŸ’¡ íŒ: ë„ë¡œëŠ” ê´œì°®ìœ¼ë‚˜ ì¥ì†Œê°€ ë¶ë¹•ë‹ˆë‹¤.")
                
            print("="*50 + "\n")

        except Exception as e:
            print(f"  Error: {e}")
            break

    print("\nThank you for using Seoul Dual Congestion Predictor!")