import os
os.environ["JAVA_OPTS"] = "-Xmx8G"
os.environ["JAVA_HOME"] = r"C:\Program Files\Java\jdk-21.0.10"

from google import genai
import zipfile
import json
import pandas as pd
import geopandas as gpd
import math
from datetime import datetime, timedelta
from dotenv import load_dotenv
from ortools.constraint_solver import routing_enums_pb2, pywrapcp
import time
from r5py import TransportNetwork, TravelTimeMatrix, DetailedItineraries, TransportMode

# ============================================================
# ì „ì—­ ìƒìˆ˜ / ìºì‹œ
# ============================================================
DETAILED_PATH_CACHE = {}

WALK_ONLY_THRESHOLD_MIN = 12   # ìµœì†Œê°’
WALK_ONLY_THRESHOLD_MAX = 18   # ìµœëŒ€ê°’

MAX_TRANSFERS = 2
MAX_TRAVEL_TIME_MIN = 90

# # ============================================================
# # API ì„¤ì •
# # ============================================================

# load_dotenv()
# API = os.getenv("API_KEY")

# client = genai.Client(api_key=API)

# # ============================================================
# # ë°ì´í„° ë¡œë“œ
# # ============================================================

# df = pd.read_excel("places_3000.xlsx")

# area = input("ì—¬í–‰í•  ì§€ì—­ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì¢…ë¡œêµ¬): ")

# filtered_spot = df[(df["area"] == f"{area}") & (df["category"] != "ì‹ë‹¹")][["name", "lat", "lng"]]
# filtered_restaurant = df[(df["area"] == f"{area}") & (df["category"] == "ì‹ë‹¹")][["name", "lat", "lng"]]
# filtered_accom = df[(df["area"] == f"{area}") & (df["category"] == "ìˆ™ë°•")][["name", "lat", "lng"]]

# places = filtered_spot.to_dict(orient="records")
# restaurants = filtered_restaurant.to_dict(orient="records")
# accommodations = filtered_accom.to_dict(orient="records")

# ============================================================
# ë‚ ì§œ ê³„ì‚°
# ============================================================

start_date = input("ì—¬í–‰ ì‹œì‘ ì¼ì (ì˜ˆ: 2026-01-20): ")
end_date = input("ì—¬í–‰ ì¢…ë£Œ ì¼ì (ì˜ˆ: 2026-01-25): ")


start = datetime.strptime(start_date, "%Y-%m-%d")
end = datetime.strptime(end_date, "%Y-%m-%d")
days = (end - start).days + 1

print(f"ì´ ì—¬í–‰ ì¼ìˆ˜: {days}")

# # ============================================================
# # í”„ë¡¬í”„íŠ¸
# # ============================================================

# schema = """
# {
#   "plans": {
#     "day1": {
#       "route": [
#         {"name": "...", "category": "...", "lat": 0.0, "lng": 0.0}
#       ],
#       "restaurants": [
#         {"name": "...", "category": "ì‹ë‹¹", "lat": 0.0, "lng": 0.0}
#       ],
#       "accommodations": [
#         {"name": "...", "category": "ìˆ™ë°•", "lat": 0.0, "lng": 0.0}
#       ]
#     }
#   }
# }
# """

# system_prompt = f"""
# ë„ˆëŠ” ì„œìš¸ ì—¬í–‰ ê²½ë¡œ ìƒì„±ê¸°ë‹¤.

# ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•œë‹¤.

# {schema}

# ê·œì¹™:
# - ì…ë ¥ëœ days ë§Œí¼ day1, day2, ... ìƒì„±
# - ì—¬í–‰ ì‹œì‘ ì¼ì : {start_date}, ì—¬í–‰ ì¢…ë£Œ ì¼ì : {end_date}
# - ë§¤ì¼ ê´€ê´‘ì§€ 5ê³³ + ì‹ë‹¹ 2ê³³ êµ¬ì„±
# - routeì—ëŠ” places ëª©ë¡ì—ì„œë§Œ ì„ íƒ
# - restaurantsì—ëŠ” restaurants ëª©ë¡ì—ì„œë§Œ ì„ íƒ
# - accommodationsì—ëŠ” accommodations ëª©ë¡ì—ì„œë§Œ ì„ íƒ
# - routeëŠ” ì´ë™ ë™ì„ ì„ ê³ ë ¤í•˜ì—¬ ë°©ë¬¸ ìˆœì„œ ìµœì í™”
# - restaurantsëŠ” í•´ë‹¹ dayì˜ ë§ˆì§€ë§‰ ê´€ê´‘ì§€ì™€ ê°€ê¹Œìš´ ìˆœì„œë¡œ 2ê³³ ì„ íƒ
# - accommodationsëŠ” í•´ë‹¹ dayì˜ ë§ˆì§€ë§‰ ê´€ê´‘ì§€ì™€ ê°€ê¹Œìš´ ìˆœì„œë¡œ 1ê³³ ì„ íƒ
# - ë§ˆì§€ë§‰ ë‚ ì—ëŠ” accommodations í¬í•¨í•˜ì§€ ì•ŠìŒ
# - ì„¤ëª… ë¬¸ì¥ì€ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤
# - ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤
# """

# user_prompt = {
#     "days": days,
#     "start_location": {"lat": 37.5547, "lng": 126.9706},
#     "places": places[:6 * days * 3],
#     "restaurants": restaurants[:3 * days * 3],
#     "accommodations": accommodations[:days * 3]
# }

# prompt = system_prompt + "\n\n" + json.dumps(user_prompt, ensure_ascii=False)

# # ============================================================
# # Gemini í˜¸ì¶œ
# # ============================================================

# start_time = time.time()
# response = client.models.generate_content(model="gemini-2.5-flash-lite", contents=prompt)
# elapsed = time.time() - start_time

# print("â± Gemini ì‘ë‹µ ì‹œê°„:", round(elapsed, 3), "ì´ˆ")

# # ============================================================
# # JSON ì¶”ì¶œ
# # ============================================================

# def extract_json(text):
#     if not text:
#         raise ValueError("Gemini ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

#     text = text.strip()

#     if text.startswith("```"):
#         text = text.split("```")[1]

#     start = text.find("{")
#     end = text.rfind("}") + 1

#     if start == -1 or end == -1:
#         raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨:\n" + text)

#     return json.loads(text[start:end])

# # ============================================================
# # ì„¤ì •
# # ============================================================

LUNCH_WINDOW = ("11:20", "13:20")
DINNER_WINDOW = ("17:40", "19:30")
first_day_start_str = input("ì—¬í–‰ ì²«ë‚  ì‹œì‘ ì‹œê°„ (ì˜ˆ: 14:00) : ").strip()
last_day_end_str = input("ì—¬í–‰ ë§ˆì§€ë§‰ ë‚  ì¢…ë£Œ ì‹œê°„ (ì˜ˆ: 18:00) : ").strip()

default_start_str = "10:00"
default_end_str = "21:00"

if not first_day_start_str: first_day_start_str = default_start_str
if not last_day_end_str: last_day_end_str = default_end_str

FIXED_EVENTS = []

has_fixed = input("ê³ ì • ì¼ì •ì´ ìˆë‚˜ìš”? (y/n): ").strip().lower()

if has_fixed == "y":
    while True:
        FIXED_DATE = input("ê³ ì • ì¼ì • ë‚ ì§œ (ì˜ˆ: 2026-01-21): ")
        TITLE = input("ê³ ì • ì¼ì • ì œëª© (ì˜ˆ: ê³µì—°): ")
        FIXED_START = input("ì‹œì‘ ì‹œê°„ (ì˜ˆ: 15:00): ")
        FIXED_END = input("ì¢…ë£Œ ì‹œê°„ (ì˜ˆ: 16:30): ")

        FIXED_EVENTS.append({
            "date": FIXED_DATE,
            "title": TITLE,
            "start": FIXED_START,
            "end": FIXED_END
        })

        if input("ê³„ì† ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower() != "y":
            break


stay_time_map = {
    "ê´€ê´‘ì§€": 90,
    "ì¹´í˜": 50,
    "ì‹ë‹¹": 70,
    "ë°•ë¬¼ê´€": 120,
    "ê³µì›": 60,
    "ì‹œì¥": 80,
    "ìˆ™ë°•": 0
}

# ============================================================
# ìœ í‹¸
# ============================================================

def parse_time(t):
    return datetime.strptime(t, "%H:%M")

def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # km
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dlambda = math.radians(lon2 - lon1)

    a = math.sin(dphi / 2) ** 2 + \
        math.cos(phi1) * math.cos(phi2) * math.sin(dlambda / 2) ** 2
    return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1 - a))

def approx_walk_minutes(start, end):
    dist_km = haversine(
        start["lat"], start["lng"],
        end["lat"], end["lng"]
    )
    return dist_km * 12  # 1km â‰ˆ 12ë¶„

def dynamic_walk_threshold(dist_km):
    if dist_km < 0.6:
        return WALK_ONLY_THRESHOLD_MAX   # 18
    elif dist_km < 1.2:
        return 15
    else:
        return WALK_ONLY_THRESHOLD_MIN   # 12

def travel_minutes(p1, p2):
    if p1["lat"] is None or p2["lat"] is None:
        return 0
    dist = haversine(p1["lat"], p1["lng"], p2["lat"], p2["lng"])
    return int(dist / 30 * 60)  # í‰ê·  30km/h

def get_fixed_events_for_day(fixed_events, target_date):
    return [e for e in fixed_events if e["date"] == target_date]

def duration_to_minutes(val):
    if val is None or pd.isna(val):
        return 0

    # 1ï¸âƒ£ pandas Timedelta
    if hasattr(val, "total_seconds"):
        return int(val.total_seconds() / 60)

    # 2ï¸âƒ£ ë¬¸ìì—´ "0 days HH:MM:SS"
    if isinstance(val, str) and "day" in val:
        try:
            td = pd.to_timedelta(val)
            return int(td.total_seconds() / 60)
        except Exception:
            return 0

    # 3ï¸âƒ£ ìˆ«ì
    try:
        return int(float(val))
    except Exception:
        return 0

# ============================================================
# r5py ë³€ìˆ˜(ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰) / Java ì„¤ì¹˜ í•„ìˆ˜
# ============================================================
def load_transport_network(osm_path, gtfs_paths, pickle_path="seoul_tn_cached.pkl"):
    # pickleì´ ì¡´ì¬í•˜ê³  ì¬ìƒì„± ì˜µì…˜ì´ êº¼ì ¸ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(pickle_path):
        print(f"ğŸ“¦ Pickle íŒŒì¼ '{pickle_path}' ë¡œë“œ ì¤‘...")
        tn = TransportNetwork.__new__(TransportNetwork)
        tn._transport_network = TransportNetwork._load_pickled_transport_network(self=TransportNetwork, path=pickle_path)
        print("âœ… ë¡œë“œ ì™„ë£Œ")
        return tn

    # pickle ì—†ê±°ë‚˜ force_rebuild=True ë©´ ìƒˆë¡œ ìƒì„±
    print("ğŸš€ TransportNetwork ìƒˆë¡œ ìƒì„± ì¤‘... (ì‹œê°„ ê±¸ë¦¼)")
    tn = TransportNetwork(osm_path, gtfs_paths)

    # ìƒì„± í›„ pickle ì €ì¥
    try:
        tn._save_pickled_transport_network(path=pickle_path, transport_network=tn)
        print(f"ğŸ’¾ ìƒì„± ì™„ë£Œ í›„ pickle ì €ì¥: '{pickle_path}'")
    except Exception as e:
        print(f"âš ï¸ pickle ì €ì¥ ì‹¤íŒ¨: {e}")

    return tn

osm_file = "./data/seoul_osm_v.pbf"
gtfs_files = ["./data/seoul_area_gtfs.zip"]

start_tn = time.time()
transport_network = load_transport_network(osm_file, gtfs_files)
end_tn = time.time()
print(f"â± TransportNetwork ë¡œë“œ/ìƒì„± ì‹œê°„: {round(end_tn - start_tn, 2)}ì´ˆ")

# ============================================================
# stops, routes ë§¤ì¹­
# ============================================================
# stops.txt ë¡œë“œ ë¶€ë¶„ ìˆ˜ì •
with zipfile.ZipFile("./data/seoul_area_gtfs.zip") as z:
    with z.open("stops.txt") as f:
        stops_df = pd.read_csv(f, dtype={'stop_id': str}) # IDë¥¼ ì²˜ìŒë¶€í„° ë¬¸ìì—´ë¡œ ì½ê¸°

# ë”•ì…”ë„ˆë¦¬ ìƒì„± ì‹œ ê³µë°± ì œê±° ë° í™•ì‹¤í•œ ë¬¸ìì—´ ì²˜ë¦¬
STOP_ID_TO_NAME = {
    str(row['stop_id']).strip(): str(row['stop_name']).strip() 
    for _, row in stops_df.iterrows()
}

with zipfile.ZipFile("./data/seoul_area_gtfs.zip") as z:
    with z.open("routes.txt") as f:
        routes_df = pd.read_csv(f)

ROUTE_ID_TO_NAME = dict(
    zip(routes_df["route_id"].astype(str), routes_df["route_short_name"].astype(str))
)

def get_stop_name(stop_id):
    if pd.isna(stop_id):
        return None
    
    # 1. ìˆ«ì/ë¬¸ìì—´ í˜¼ìš© ëŒ€ì‘: "10100001.0" ê°™ì€ ë°ì´í„°ë¥¼ "10100001"ë¡œ ë³€í™˜
    try:
        # ì†Œìˆ˜ì ì´ í¬í•¨ëœ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ float -> int -> str ìˆœìœ¼ë¡œ ë³€í™˜
        safe_id = str(int(float(stop_id))).strip()
    except (ValueError, TypeError):
        safe_id = str(stop_id).strip()

    # 2. ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ
    name = STOP_ID_TO_NAME.get(safe_id)
    
    # 3. ì„œìš¸ GTFS íŠ¹ì„±: ì•ìë¦¬ì— 0ì´ í¬í•¨ëœ 5ìë¦¬ ID ëŒ€ì‘ (ì˜ˆ: "05123")
    if not name and len(safe_id) < 5:
        name = STOP_ID_TO_NAME.get(safe_id.zfill(5))
        
    return name

def safe_stop_name(val):
    if pd.isna(val):
        return None
    try:
        return get_stop_name(str(int(float(val))))
    except Exception:
        return get_stop_name(str(val))

def get_route_name(route_id):
    if pd.isna(route_id):
        return None
    try:
        safe_id = str(int(float(route_id)))
    except Exception:
        safe_id = str(route_id)
        
    return ROUTE_ID_TO_NAME.get(safe_id)

# ============================================================
# r5py ê¸°ë°˜ ì´ë™ ì‹œê°„ ê³„ì‚° í•¨ìˆ˜ (ìˆ˜ì •ë¨)
# ============================================================
def get_r5py_matrix(nodes, departure_time):
    """
    ëª¨ë“  ë…¸ë“œ ê°„ì˜ ëŒ€ì¤‘êµí†µ ì´ë™ ì‹œê°„ í–‰ë ¬ì„ í•œêº¼ë²ˆì— ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    valid_nodes = [n for n in nodes if n["lat"] is not None]
    if len(valid_nodes) < 2:
        return {}

    gdf = gpd.GeoDataFrame(
        valid_nodes,
        geometry=gpd.points_from_xy(
            [n['lng'] for n in valid_nodes],
            [n['lat'] for n in valid_nodes]
        ),
        crs="EPSG:4326"
    )

    try:
        matrix = TravelTimeMatrix(
            transport_network,
            origins=gdf,
            destinations=gdf,
            departure=departure_time,
            transport_modes=[TransportMode.WALK, TransportMode.TRANSIT]
        )
    except Exception as e:
        print(f"âš ï¸ í–‰ë ¬ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return {}

    r5_travel_times = {}
    for row in matrix.itertuples():
        if not pd.isna(row.travel_time):
            r5_travel_times[(int(row.from_id), int(row.to_id))] = int(row.travel_time)

    return r5_travel_times

# ============================================================
# ìƒì„¸ ê²½ë¡œ ì¶”ì¶œ í•¨ìˆ˜ (ìˆ˜ì •ë¨)
# ============================================================

def make_cache_key(start_node, end_node, departure_time):
    """
    ì •ë¥˜ì¥ ë‹¨ìœ„ + ì‹œê°„ ë²„í‚· ìºì‹œ í‚¤
    """
    hour_bucket = departure_time.hour

    return (
        start_node.get("nearest_stop_id") or start_node.get("id"),
        end_node.get("nearest_stop_id") or end_node.get("id"),
        hour_bucket
    )

def get_all_detailed_paths(trip_legs, departure_time):
    """
    í•„ìš”í•œ êµ¬ê°„ë§Œ ìƒì„¸ ê²½ë¡œ ê³„ì‚° + ìºì‹± + ì„  ì»· ìµœì í™”
    """
    if not trip_legs:
        return {}

    path_map = {}
    origins_list, dests_list = [], []
    valid_pairs = []

    # ===============================
    # 1ï¸âƒ£ ì„  í•„í„°ë§
    # ===============================
    for start_node, end_node in trip_legs:
        if start_node['lat'] is None or end_node['lat'] is None:
            continue
        if start_node['id'] == end_node['id']:
            continue

        # ê±°ë¦¬ ê¸°ë°˜ ë„ë³´ ì»·
        approx_min = approx_walk_minutes(start_node, end_node)
        if approx_min <= dynamic_walk_threshold(
            haversine(
                start_node["lat"], start_node["lng"],
                end_node["lat"], end_node["lng"]
            )
        ):
            path_map[(start_node['id'], end_node['id'])] = f"ë„ë³´ {round(approx_min)}ë¶„"
            continue

        # ìºì‹œ í‚¤ (ì •ë¥˜ì¥ + ì‹œê°„ ë²„í‚·)
        cache_key = make_cache_key(start_node, end_node, departure_time)
        if cache_key in DETAILED_PATH_CACHE:
            path_map[(start_node['id'], end_node['id'])] = DETAILED_PATH_CACHE[cache_key]
            continue

        origins_list.append(start_node)
        dests_list.append(end_node)
        valid_pairs.append((start_node['id'], end_node['id'], cache_key))

    if not origins_list:
        return path_map

    # ===============================
    # 2ï¸âƒ£ GeoDataFrame ìƒì„±
    # ===============================
    origins_gdf = gpd.GeoDataFrame(
        origins_list,
        geometry=gpd.points_from_xy(
            [n['lng'] for n in origins_list],
            [n['lat'] for n in origins_list]
        ),
        crs="EPSG:4326"
    )
    origins_gdf["id"] = [n["id"] for n in origins_list]

    dests_gdf = gpd.GeoDataFrame(
        dests_list,
        geometry=gpd.points_from_xy(
            [n['lng'] for n in dests_list],
            [n['lat'] for n in dests_list]
        ),
        crs="EPSG:4326"
    )
    dests_gdf["id"] = [n["id"] for n in dests_list]

    # ===============================
    # 3ï¸âƒ£ r5py í˜¸ì¶œ (ì œí•œ ì ìš©)
    # ===============================
    try:
        computer = DetailedItineraries(
            transport_network,
            origins=origins_gdf,
            destinations=dests_gdf,
            departure=departure_time,
            transport_modes=[TransportMode.WALK, TransportMode.TRANSIT],
            max_public_transport_rides=MAX_TRANSFERS,
            max_time=timedelta(minutes=MAX_TRAVEL_TIME_MIN)
        )
    except Exception as e:
        print(f"âš ï¸ ìƒì„¸ ê²½ë¡œ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return path_map

    if computer.empty:
        return path_map

    # ===============================
    # 4ï¸âƒ£ Helper
    # ===============================
    def get_val(row, candidates, default=None):
        for c in candidates:
            if c in row.index and pd.notna(row[c]):
                v = str(row[c]).strip()
                if v:
                    return v
        return default

    mode_col = 'transport_mode' if 'transport_mode' in computer.columns else 'mode'

    # ===============================
    # 5ï¸âƒ£ ê²°ê³¼ íŒŒì‹±
    # ===============================
    for (from_id, to_id), group in computer.groupby(['from_id', 'to_id']):
        best_route, best_time = None, float("inf")

        for _, opt in group.groupby("option"):
            total = sum(
                max(1, duration_to_minutes(get_val(leg, ['travel_time', 'duration'], 0)))
                for _, leg in opt.iterrows()
            )
            if total < best_time:
                best_time, best_route = total, opt

        if best_route is None:
            continue

        segments = []
        for _, leg in best_route.iterrows():
            raw_mode = str(leg[mode_col]).upper()
            dur = max(1, duration_to_minutes(get_val(leg, ['travel_time', 'duration'], 0)))

            if 'WALK' in raw_mode:
                segments.append(f"ë„ë³´ {dur}ë¶„")
                continue

            # [ìˆ˜ì •] ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ëª…ì¸ start_stop_idì™€ end_stop_idë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            # r5py ë²„ì „ì´ë‚˜ ì„¤ì •ì— ë”°ë¼ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìœ ì—°í•˜ê²Œ ëŒ€ì²˜í•©ë‹ˆë‹¤.
            from_stop_id = get_val(leg, ['start_stop_id', 'from_stop_id'])
            to_stop_id = get_val(leg, ['end_stop_id', 'to_stop_id'])

            # ë”•ì…”ë„ˆë¦¬ì—ì„œ ì´ë¦„ ì¡°íšŒ
            from_stop = get_stop_name(from_stop_id) or f"ë¯¸í™•ì • ì •ë¥˜ì¥({from_stop_id})"
            to_stop = get_stop_name(to_stop_id) or f"ë¯¸í™•ì • ì •ë¥˜ì¥({to_stop_id})"
            
            route_id = get_val(leg, ['route_id'])
            route_name = (
                get_val(leg, ['route_short_name']) or 
                get_route_name(route_id) or 
                'ëŒ€ì¤‘êµí†µ'
            )

            mode_label = "ì§€í•˜ì² " if any(x in raw_mode for x in ['SUBWAY', 'RAIL', 'METRO']) else "ë²„ìŠ¤"
            segments.append(f"[{mode_label}][{route_name}] {from_stop} â†’ {to_stop} ({dur}ë¶„)")

        path_text = " > ".join(segments)

        # ìºì‹œ ì €ì¥
        cache_key = make_cache_key(
            {"nearest_stop_id": str(from_id)},
            {"nearest_stop_id": str(to_id)},
            departure_time
        )
        DETAILED_PATH_CACHE[cache_key] = path_text
        path_map[(int(from_id), int(to_id))] = path_text

    return path_map

# ============================================================
# ë…¸ë“œ ìƒì„±
# ============================================================

def build_fixed_nodes(fixed_events, day_start_dt):
    nodes = []
    BUFFER = 15

    for event in fixed_events:
        event_start = parse_time(event["start"])
        event_end = parse_time(event["end"])

        orig_start_min = int((event_start - day_start_dt).total_seconds() / 60)
        orig_end_min = int((event_end - day_start_dt).total_seconds() / 60)

        raw_start_min = orig_start_min - BUFFER
        buffered_start_min = max(0, raw_start_min)

        orig_duration = orig_end_min - orig_start_min
        secured_front_buffer = orig_start_min - buffered_start_min
        final_stay = secured_front_buffer + orig_duration + BUFFER

        nodes.append({
            "name": event["title"],
            "category": "ê³ ì •ì¼ì •",
            "lat": None,
            "lng": None,
            "stay": final_stay,
            "type": "fixed",
            "window": (buffered_start_min, buffered_start_min + 10),
            "orig_time_str": f"{event['start']} - {event['end']}"
        })

    return nodes


def build_nodes(places, restaurants, fixed_events, day_start_dt):
    nodes = []

    if places:
        first_place = places[0]
    else:
        first_place = {"lat": 37.5665, "lng": 126.9780}

    nodes.append({
        "name": "ì‹œì‘ì ",
        "category": "ì¶œë°œ",
        "lat": first_place["lat"],
        "lng": first_place["lng"],
        "stay": 0,
        "type": "depot"
    })

    for p in places:
        nodes.append({
            "name": p["name"],
            "category": p["category"],
            "lat": p["lat"],
            "lng": p["lng"],
            "stay": stay_time_map.get(p["category"], 60),
            "type": "spot"
        })

    if restaurants:
        nodes.append({ "name": restaurants[0]["name"], "category": "ì‹ë‹¹", "lat": restaurants[0]["lat"], "lng": restaurants[0]["lng"], "stay": 70, "type": "lunch" })
        nodes.append({ "name": restaurants[1]["name"], "category": "ì‹ë‹¹", "lat": restaurants[1]["lat"], "lng": restaurants[1]["lng"], "stay": 70, "type": "dinner" })

    nodes.extend(build_fixed_nodes(fixed_events, day_start_dt))
    return nodes


# ============================================================
# Time Window ì„¤ì •
# ============================================================

def build_time_windows(nodes, day_start_dt):
    windows = []

    def get_relative_window(time_str):
        target_time = parse_time(time_str)
        return int((target_time - day_start_dt).total_seconds() / 60)

    lunch_start = get_relative_window(LUNCH_WINDOW[0])
    lunch_end = get_relative_window(LUNCH_WINDOW[1])
    dinner_start = get_relative_window(DINNER_WINDOW[0])
    dinner_end = get_relative_window(DINNER_WINDOW[1])

    for n in nodes:
        if n["type"] == "lunch":
            windows.append((lunch_start, lunch_end))
        elif n["type"] == "dinner":
            windows.append((dinner_start, dinner_end))
        elif n["type"] == "fixed":
            windows.append(n["window"])
        else:
            windows.append((0, 24 * 60))

    return windows


# ============================================================
# OR-Tools ëª¨ë¸
# ============================================================

def optimize_day(places, restaurants, fixed_events, start_time_str, target_date_str, end_time_str=None):
    # ==========================================
    # 1. ì´ˆê¸° ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„
    # ==========================================
    TRAVEL_BUFFER = 5  # ì´ë™ í›„ ì—¬ìœ  ì‹œê°„ (ë¶„)

    day_start_dt = datetime.strptime(start_time_str, "%H:%M")

    # r5py ê³„ì‚°ìš© ë‚ ì§œ (GTFS ë°ì´í„° ìœ íš¨ ê¸°ê°„ ë‚´ì˜ ë‚ ì§œ ì‚¬ìš©)
    # start_dateëŠ” ì „ì—­ ë³€ìˆ˜ë¼ê³  ê°€ì •
    SAFE_GTFS_DATE = start_date 
    r5_date_obj = datetime.strptime(SAFE_GTFS_DATE, "%Y-%m-%d")
    r5_departure_dt = datetime.combine(r5_date_obj, datetime.strptime("11:00", "%H:%M").time())

    # ê²°ê³¼ ì¶œë ¥ìš© ì‹¤ì œ ë‚ ì§œ
    display_date_obj = datetime.strptime(target_date_str, "%Y-%m-%d")
    display_start_dt = datetime.combine(display_date_obj, day_start_dt.time())

    # í•˜ë£¨ ìµœëŒ€ ì‹œê°„(ë¶„) ê³„ì‚°
    if end_time_str:
        day_end_dt = datetime.strptime(end_time_str, "%H:%M")
        max_horizon_minutes = int((day_end_dt - day_start_dt).total_seconds() / 60)
        if max_horizon_minutes < 0:
            max_horizon_minutes = 24 * 60
    else:
        max_horizon_minutes = 24 * 60

    # ë…¸ë“œ ìƒì„± ë° ID ë¶€ì—¬
    nodes = build_nodes(places, restaurants, fixed_events, day_start_dt)
    for idx, node in enumerate(nodes):
        node["id"] = idx

    n = len(nodes)

    # ==========================================
    # 2. ì´ë™ ì‹œê°„ í–‰ë ¬(Matrix) ê³„ì‚°
    # ==========================================
    # r5pyë¡œ ëŒ€ì¤‘êµí†µ ì‹œê°„ ê³„ì‚°
    r5_travel_times = get_r5py_matrix(nodes, r5_departure_dt)

    # OR-Toolsìš© ìµœì¢… í–‰ë ¬ ìƒì„± (r5py ì‹¤íŒ¨ ì‹œ ì§ì„ ê±°ë¦¬ ëŒ€ì²´ ë¡œì§ í¬í•¨)
    time_matrix = [[0]*n for _ in range(n)]
    for i in range(n):
        for j in range(n):
            if i == j:
                continue

            travel_val = r5_travel_times.get((i, j))
            if travel_val is None:
                travel_val = travel_minutes(nodes[i], nodes[j]) # í•˜ë²„ì‚¬ì¸ ê±°ë¦¬ ê¸°ë°˜ ì˜ˆë¹„ ê³„ì‚°

            # ê³ ì • ì¼ì • ê´€ë ¨ ì´ë™ ì‹œê°„ ë³´ì • (ì¶œë°œì§€->ê³ ì •ì¼ì •ì€ 0ë¶„ ë“±)
            is_fixed_involved = (nodes[i]["type"] == "fixed" or nodes[j]["type"] == "fixed")
            if is_fixed_involved:
                if nodes[i]["type"] == "depot" and nodes[j]["type"] == "fixed":
                    travel_val = 0
                else:
                    travel_val = max(travel_val, 20) # ê³ ì •ì¼ì • ì´ë™ ìµœì†Œ ì‹œê°„ ë³´ì¥

            # ì´ë™ì‹œê°„ + ì²´ë¥˜ì‹œê°„ + ë²„í¼
            time_matrix[i][j] = nodes[i]["stay"] + int(travel_val) + TRAVEL_BUFFER

    # ==========================================
    # 3. OR-Tools ëª¨ë¸ ì„¤ì •
    # ==========================================
    manager = pywrapcp.RoutingIndexManager(n, 1, 0)
    routing = pywrapcp.RoutingModel(manager)

    def time_callback(from_idx, to_idx):
        return time_matrix[manager.IndexToNode(from_idx)][manager.IndexToNode(to_idx)]

    transit_callback = routing.RegisterTransitCallback(time_callback)
    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback)
    
    # Time Dimension ì¶”ê°€ (ì—¬ê¸°ì„œ time_dim ë³€ìˆ˜ ìƒì„±ë¨)
    routing.AddDimension(transit_callback, 30, max_horizon_minutes, False, "Time")
    time_dim = routing.GetDimensionOrDie("Time")

    # í˜ë„í‹° ë° íƒ€ì„ ìœˆë„ìš° ì„¤ì •
    penalty_spot = 100000
    penalty_meal = 1000000
    solver = routing.solver()

    time_windows = build_time_windows(nodes, day_start_dt)

    for i, node in enumerate(nodes):
        index = manager.NodeToIndex(i)
        if node["type"] == "depot":
            continue

        window = time_windows[i]

        # ê³ ì • ì¼ì • ì²˜ë¦¬
        if node["type"] == "fixed":
            safe_start = max(0, min(window[0], max_horizon_minutes))
            safe_end = max(safe_start, min(window[1], max_horizon_minutes))
            time_dim.CumulVar(index).SetRange(safe_start, safe_end)
            continue

        # ì¼ë°˜ ì¼ì • ì²˜ë¦¬
        overlap_start = max(0, window[0])
        overlap_end = min(max_horizon_minutes, window[1])

        if overlap_start > overlap_end:
            routing.AddDisjunction([index], 0)
            solver.Add(routing.VehicleVar(index) == -1)
            continue

        time_dim.CumulVar(index).SetRange(overlap_start, overlap_end)

        if node["type"] == "spot":
            routing.AddDisjunction([index], penalty_spot)
        elif node["type"] in ["lunch", "dinner"]:
            routing.AddDisjunction([index], penalty_meal)

    # ==========================================
    # 4. ì†”ë£¨ì…˜ íƒìƒ‰ (Solve)
    # ==========================================
    search_params = pywrapcp.DefaultRoutingSearchParameters()
    search_params.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC
    search_params.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH
    search_params.time_limit.seconds = 1

    solution = routing.SolveWithParameters(search_params)
    if not solution:
        return []

    # ==========================================
    # 5. ê²°ê³¼ ì²˜ë¦¬ (ì†ë„ ê°œì„ ëœ ë¶€ë¶„)
    # ==========================================
    
    # 5-1. ë°©ë¬¸ ìˆœì„œ ë° ì‹œê°„ ì •ë³´ ë¨¼ì € ì¶”ì¶œ
    index = routing.Start(0)
    visited_nodes = []
    
    while not routing.IsEnd(index):
        node_idx = manager.IndexToNode(index)
        t_start_min = solution.Value(time_dim.CumulVar(index))
        node = nodes[node_idx]
        
        # ê³„ì‚°ëœ ë„ì°© ì‹œê°„(ë¶„)ì„ ë…¸ë“œ ê°ì²´ì— ì„ì‹œ ì €ì¥
        node['arrival_min'] = t_start_min
        visited_nodes.append(node)
        
        index = solution.Value(routing.NextVar(index))

    # 5-2. ì´ë™ êµ¬ê°„(Leg) ë¦¬ìŠ¤íŠ¸ ìƒì„±
    trip_legs = []
    for i in range(len(visited_nodes) - 1):
        start_node = visited_nodes[i]
        end_node = visited_nodes[i+1]
        trip_legs.append((start_node, end_node))

    # 5-3. ìƒì„¸ ê²½ë¡œ 'ì¼ê´„' ê³„ì‚° (Batch Processing)
    # ì´ ë¶€ë¶„ì´ ê¸°ì¡´ ë£¨í”„ ë°©ì‹ë³´ë‹¤ í›¨ì”¬ ë¹ ë¦…ë‹ˆë‹¤.
    print("ğŸš€ ì „ì²´ ìƒì„¸ ê²½ë¡œ ì¼ê´„ ê³„ì‚° ì¤‘...")
    batch_start = time.time()
    
    # ì•ì„œ ì •ì˜í•œ get_all_detailed_paths í•¨ìˆ˜ í˜¸ì¶œ
    path_map = get_all_detailed_paths(trip_legs, r5_departure_dt)
    
    print(f"(ìƒì„¸ ê²½ë¡œ ì¼ê´„ ê³„ì‚° ì‹œê°„: {round(time.time() - batch_start, 2)}ì´ˆ)")

    # 5-4. ìµœì¢… íƒ€ì„ë¼ì¸ ì¡°ë¦½ (ìˆ˜ì • ë²„ì „)
    timeline = []
    
    # ì‹œì‘ì (depot)ì„ ì œì™¸í•œ ì‹¤ì œ ë°©ë¬¸ì§€ë“¤ë§Œ ì¶”ì¶œ
    actual_visits = [n for n in visited_nodes if n["type"] != "depot"]

    for i, node in enumerate(actual_visits):
        # 1. ë°©ë¬¸ ì‹œê°„ ê³„ì‚°
        if node["type"] == "fixed":
            time_str = node["orig_time_str"]
        else:
            visit_start = display_start_dt + timedelta(minutes=node['arrival_min'])
            visit_end = visit_start + timedelta(minutes=node["stay"])
            time_str = f"{visit_start.strftime('%H:%M')} - {visit_end.strftime('%H:%M')}"

        # 2. ì´ì „ ì¥ì†Œë¡œë¶€í„°ì˜ ê²½ë¡œ ê³„ì‚°
        transit_info = ""
        if i > 0:
            prev_node = actual_visits[i-1]
            dist = haversine(prev_node['lat'], prev_node['lng'], node['lat'], node['lng'])
            
            # [í•µì‹¬] ê±°ë¦¬ê°€ 100m ë¯¸ë§Œì´ë©´ ê±´ë¬¼ ë‚´ ì´ë™ìœ¼ë¡œ ê°„ì£¼
            if dist < 0.1: 
                transit_info = "ë„ë³´ ì´ë™ (ê±´ë¬¼ ë‚´ ì´ë™)"
            else:
                # r5py ê²½ë¡œê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì“°ê³ , ì—†ìœ¼ë©´ ë„ë³´ ê³„ì‚°
                r5_path = path_map.get((prev_node['id'], node['id']))
                if r5_path:
                    transit_info = r5_path
                else:
                    walk_min = approx_walk_minutes(prev_node, node)
                    transit_info = f"ë„ë³´ ì´ë™ (ì•½ {round(walk_min)}ë¶„)"

        timeline.append({
            "name": node["name"],
            "category": node["category"],
            "time": time_str,
            "transit_to_here": transit_info
        })

    return timeline

# ============================================================
# ì¼ì • íƒ€ì„ë¼ì¸ jsonì— ì¶”ê°€ (ì‹¤í–‰ë¶€ ìˆ˜ì •)
# ============================================================

if __name__ == "__main__":
    # result = extract_json(response.text)
    # with open("result.json", "w", encoding="utf-8") as f:
    #     json.dump(result, f, ensure_ascii=False, indent=2)
    
    # ë˜ëŠ” ê¸°ì¡´ result ì‚¬ìš©
    
    result = json.load(open("result.json", "r", encoding="utf-8"))
    plans = result["plans"]
    current_date = start

    # ì „ì²´ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ í™•ì¸
    day_keys = list(plans.keys())
    total_days = len(day_keys)

    for i, day_key in enumerate(day_keys):
        print(f"\nğŸ“… {day_key} ì¼ì • ìµœì í™”")

        day_data = plans[day_key]
        day_places = day_data["route"]
        day_restaurants = day_data["restaurants"]
        
        # [ì¤‘ìš”] í˜„ì¬ ë£¨í”„ì˜ ë‚ ì§œ ë¬¸ìì—´ (YYYY-MM-DD)
        day_str = current_date.strftime("%Y-%m-%d")
        day_fixed_events = get_fixed_events_for_day(FIXED_EVENTS, day_str)

        # 1. ì‹œì‘/ì¢…ë£Œ ì‹œê°„ ê²°ì •
        if i == 0:
            todays_start = first_day_start_str
        else:
            todays_start = default_start_str

        if i == total_days - 1:
            todays_end = last_day_end_str
        else:
            todays_end = default_end_str

        timeset = f"{todays_start} ì‹œì‘" + (f" ~ {todays_end} ì¢…ë£Œ" if todays_end else "")
        print(timeset)

        # 2. ìµœì í™” ì‹¤í–‰ (target_date_str ì¶”ê°€ ì „ë‹¬)
        start_opt = time.time()
        timeline = optimize_day(
            places=day_places,
            restaurants=day_restaurants,
            fixed_events=day_fixed_events,
            start_time_str=todays_start,
            target_date_str=day_str,  # [ìˆ˜ì •] ë‚ ì§œ ì •ë³´ ì „ë‹¬
            end_time_str=todays_end
        )
        end_opt = time.time()
        print(f"â± optimize_day ì‹¤í–‰ ì‹œê°„: {round(end_opt - start_opt, 2)}ì´ˆ")

        result["plans"][day_key]["timeset"] = timeset
        result["plans"][day_key]["timeline"] = timeline

        if not timeline:
            print("   âš  ì¡°ê±´ ë§Œì¡±í•˜ëŠ” ì¼ì • ìƒì„± ì‹¤íŒ¨")
        else:
            for i, t in enumerate(timeline):
                # 1. ê²½ë¡œ ì •ë³´ë¥¼ ë¨¼ì € ì¶œë ¥ (ì¥ì†Œ ì‚¬ì´ì˜ 'ì—°ê²°ê³ ë¦¬' ì—­í• )
                if t.get('transit_to_here') and "ì´ë™ ì—†ìŒ" not in t['transit_to_here']:
                    # ê²½ë¡œê°€ ë„ë³´ì¸ì§€ ëŒ€ì¤‘êµí†µì¸ì§€ì— ë”°ë¼ í™”ì‚´í‘œ ëŠë‚Œ ì¶”ê°€
                    prefix = "    â–¼ " 
                    print(f"{prefix}{t['transit_to_here']}")

                # 2. ê·¸ ë‹¤ìŒ ì¥ì†Œ ì •ë³´ë¥¼ ì¶œë ¥
                print(f"  [{t['time']}] {t['name']} ({t['category']})")

        current_date += timedelta(days=1)

    print("\n====== ìµœì¢… ê²°ê³¼ ======\n")
    file_path = "result_timeline.json"
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"âœ… ì¼ì •ì´ '{file_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")