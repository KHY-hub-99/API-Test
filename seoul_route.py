import os
os.environ["JAVA_OPTS"] = "-Xmx8G"
os.environ["JAVA_HOME"] = r"C:\Program Files\Java\jdk-21.0.10"

from google import genai
import zipfile
import json
import pandas as pd
import geopandas as gpd
import math
from datetime import datetime, timedelta
from dotenv import load_dotenv
from ortools.constraint_solver import routing_enums_pb2, pywrapcp
import time
from r5py import TransportNetwork, TravelTimeMatrix, DetailedItineraries, TransportMode

# ============================================================
# 1. í™˜ê²½ ì„¤ì • ë° ì „ì—­ ìƒìˆ˜
# ============================================================ 

# API í‚¤ ì„¤ì •
load_dotenv()
API_KEY = os.getenv("API_KEY")
client = genai.Client(api_key=API_KEY)

# ìºì‹œ ì €ì¥ì†Œ
DETAILED_PATH_CACHE = {}

# ë„ë³´ ì´ë™ ì œí•œ (km -> ë¶„ í™˜ì‚° ê¸°ì¤€ ë“±)
WALK_ONLY_THRESHOLD_MIN = 12   
WALK_ONLY_THRESHOLD_MAX = 18   

MAX_TRANSFERS = 3
MAX_TRAVEL_TIME_MIN = 90

# ì‹œê°„ ìœˆë„ìš° ì„¤ì •
LUNCH_WINDOW = ("11:20", "13:20")
DINNER_WINDOW = ("17:40", "19:30")

# ì¥ì†Œë³„ ì²´ë¥˜ ì‹œê°„
stay_time_map = {
    "ê´€ê´‘ì§€": 90, "ì¹´í˜": 50, "ì‹ë‹¹": 70, 
    "ë°•ë¬¼ê´€": 120, "ê³µì›": 60, "ì‹œì¥": 80, "ìˆ™ë°•": 0
}

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ
osm_file = "./data/seoul_osm_v.pbf"
gtfs_files = ["./data/seoul_area_gtfs.zip"]

# ============================================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================
def parse_time(t):
    return datetime.strptime(t, "%H:%M")

def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # km
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dlambda = math.radians(lon2 - lon1)
    a = math.sin(dphi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(dlambda / 2) ** 2
    return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1 - a))

def approx_walk_minutes(start, end):
    dist_km = haversine(start["lat"], start["lng"], end["lat"], end["lng"])
    return dist_km * 12

def dynamic_walk_threshold(dist_km):
    if dist_km < 0.6: return WALK_ONLY_THRESHOLD_MAX
    elif dist_km < 1.2: return 15
    else: return WALK_ONLY_THRESHOLD_MIN

def travel_minutes(p1, p2):
    if p1["lat"] is None or p2["lat"] is None: return 0
    dist = haversine(p1["lat"], p1["lng"], p2["lat"], p2["lng"])
    return int(dist / 30 * 60)

def get_fixed_events_for_day(fixed_events, target_date):
    return [e for e in fixed_events if e["date"] == target_date]

def duration_to_minutes(val):
    if val is None or pd.isna(val): return 0
    if hasattr(val, "total_seconds"): return int(val.total_seconds() / 60)
    if isinstance(val, str) and "day" in val:
        try: return int(pd.to_timedelta(val).total_seconds() / 60)
        except: return 0
    try: return int(float(val))
    except: return 0

def extract_json(text):
    if not text:
        raise ValueError("Gemini ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    text = text.strip()
    if text.startswith("```"):
        text = text.split("```")[1]
        if text.startswith("json"):
            text = text[4:]
    start = text.find("{")
    end = text.rfind("}") + 1
    if start == -1 or end == -1:
        raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨:\n" + text)
    return json.loads(text[start:end])

# ============================================================
# 3. êµí†µ ë°ì´í„° ë¡œë“œ (GTFS & OSM)
# ============================================================

# 3-1. TransportNetwork (r5py)
pickle_path = "./data/seoul_tn_cached.pkl"
if os.path.exists(pickle_path):
    print(f"ğŸ“¦ Pickle íŒŒì¼ ë¡œë“œ: {pickle_path}")
    start_load = time.time()
    transport_network = TransportNetwork.__new__(TransportNetwork)
    transport_network._transport_network = TransportNetwork._load_pickled_transport_network(self=TransportNetwork, path=pickle_path)
    print(f"â± ë¡œë“œ ì™„ë£Œ: {round(time.time() - start_load, 2)}ì´ˆ")
else:
    print("ğŸš€ TransportNetwork ìƒì„± ì¤‘... (ì‹œê°„ ì†Œìš”)")
    start_tn = time.time()
    transport_network = TransportNetwork(osm_file, gtfs_files)
    transport_network._save_pickled_transport_network(path=pickle_path, transport_network=transport_network)
    print(f"â± ìƒì„± ì™„ë£Œ: {round(time.time() - start_tn, 2)}ì´ˆ")

# 3-2. Stops ë¡œë“œ & ë§¤í•‘
print("ğŸš ì •ë¥˜ì¥ ë°ì´í„° ë¡œë“œ ì¤‘...")
with zipfile.ZipFile(gtfs_files[0]) as z:
    with z.open("stops.txt") as f:
        stops_df = pd.read_csv(f, dtype={'stop_id': str})

STOP_ID_TO_NAME = {str(row['stop_id']).strip(): str(row['stop_name']).strip() for _, row in stops_df.iterrows()}

def get_stop_name(stop_id):
    if pd.isna(stop_id): return None
    safe_id = str(stop_id).strip()
    try: safe_id = str(int(float(stop_id))).strip()
    except: pass
    name = STOP_ID_TO_NAME.get(safe_id)
    if not name and len(safe_id) < 5: name = STOP_ID_TO_NAME.get(safe_id.zfill(5))
    return name

# 3-3. Routes & Types ë¡œë“œ (ê°„ì„ /ì§€ì„  í•„í„°ë§ìš©)
ROUTE_TYPE_MAP = {
    11: "ê°„ì„ ", 12: "ì§€ì„ ", 13: "ìˆœí™˜", 14: "ê´‘ì—­", 15: "ë§ˆì„",
    3: "ë²„ìŠ¤", 2: "ì§€í•˜ì² ", 109: "ì§€í•˜ì² "
}

def get_route_type_str(type_code):
    return ROUTE_TYPE_MAP.get(type_code, "")

print("ğŸšŒ ë…¸ì„  ë°ì´í„° ë¡œë“œ ì¤‘...")
with zipfile.ZipFile(gtfs_files[0]) as z:
    with z.open("routes.txt") as f:
        routes_df = pd.read_csv(f)

# ID -> ì´ë¦„
ROUTE_ID_TO_NAME = dict(zip(routes_df["route_id"].astype(str), routes_df["route_short_name"].astype(str)))
# ID -> íƒ€ì… (ìˆ«ì)
ROUTE_ID_TO_TYPE = dict(zip(routes_df["route_id"].astype(str), routes_df["route_type"].fillna(3).astype(int)))

def get_route_name(route_id):
    if pd.isna(route_id): return None
    try: safe_id = str(int(float(route_id)))
    except: safe_id = str(route_id)
    return ROUTE_ID_TO_NAME.get(safe_id)

# 3-4. ì •ë¥˜ì¥ë³„ ë…¸ì„  ë§¤í•‘ (ë³‘ë ¬ ë…¸ì„  íƒìƒ‰ìš©)
STOP_ROUTE_MAP = {}
try:
    print("ğŸ”„ ì •ë¥˜ì¥-ë…¸ì„  ë§¤í•‘ ë°ì´í„° ìƒì„± ì¤‘...")
    start_map = time.time()
    with zipfile.ZipFile(gtfs_files[0]) as z:
        with z.open("trips.txt") as f:
            trips = pd.read_csv(f, usecols=["route_id", "trip_id"])
        with z.open("stop_times.txt") as f:
            stop_times = pd.read_csv(f, usecols=["trip_id", "stop_id"], dtype={"stop_id": str})
    
    merged = stop_times.merge(trips, on="trip_id")
    grouped = merged.groupby("stop_id")["route_id"].unique()
    STOP_ROUTE_MAP = {str(k).strip(): set(v) for k, v in grouped.items()}
    print(f"âœ… ë§¤í•‘ ì™„ë£Œ ({round(time.time() - start_map, 2)}ì´ˆ)")
except Exception as e:
    print(f"âš ï¸ ì •ë¥˜ì¥ ë§¤í•‘ ì‹¤íŒ¨: {e}")

# ============================================================
# 4. ê²½ë¡œ ê³„ì‚° ë° ìƒì„¸í™” (r5py)
# ============================================================
def get_r5py_matrix(nodes, departure_time):
    valid_nodes = [n for n in nodes if n["lat"] is not None]
    if len(valid_nodes) < 2: return {}

    gdf = gpd.GeoDataFrame(
        valid_nodes,
        geometry=gpd.points_from_xy([n['lng'] for n in valid_nodes], [n['lat'] for n in valid_nodes]),
        crs="EPSG:4326"
    )

    try:
        matrix = TravelTimeMatrix(
            transport_network, origins=gdf, destinations=gdf, departure=departure_time,
            transport_modes=[TransportMode.WALK, TransportMode.TRANSIT]
        )
        r5_travel_times = {}
        for row in matrix.itertuples():
            if not pd.isna(row.travel_time):
                r5_travel_times[(int(row.from_id), int(row.to_id))] = int(row.travel_time)
        return r5_travel_times
    except Exception as e:
        print(f"âš ï¸ í–‰ë ¬ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return {}

def make_cache_key(start_node, end_node, departure_time):
    return (start_node.get("id"), end_node.get("id"), departure_time.hour)

def get_all_detailed_paths(trip_legs, departure_time):
    if not trip_legs: return {}
    path_map = {}
    origins_list, dests_list = [], []

    # 1. ì„  í•„í„°ë§ (ë„ˆë¬´ ê°€ê¹Œìš°ë©´ ë„ë³´ ì²˜ë¦¬) -> ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
    for start_node, end_node in trip_legs:
        if start_node['id'] == end_node['id']: continue
        
        dist_val = haversine(start_node["lat"], start_node["lng"], end_node["lat"], end_node["lng"])
        approx_min = dist_val * 15
        # [íŒë‹¨] ê±°ë¦¬ê°€ ì§§ìœ¼ë©´(dynamic_walk_threshold ì´í•˜), ë¹„ì‹¼ r5py ê³„ì‚°ì„ ì•ˆ í•˜ê³  ë°”ë¡œ ê²°ì •í•´ë²„ë¦¼
        if approx_min <= dynamic_walk_threshold(dist_val):
            path_map[(start_node['id'], end_node['id'])] = [f"ë„ë³´ : {round(approx_min)}ë¶„"]
            continue

        cache_key = make_cache_key(start_node, end_node, departure_time)
        if cache_key in DETAILED_PATH_CACHE:
            path_map[(start_node['id'], end_node['id'])] = DETAILED_PATH_CACHE[cache_key]
            continue

        origins_list.append(start_node)
        dests_list.append(end_node)

    if not origins_list: return path_map

    # 2. r5py ìƒì„¸ ê²½ë¡œ ìš”ì²­ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
    origins_gdf = gpd.GeoDataFrame(origins_list, geometry=gpd.points_from_xy([n['lng'] for n in origins_list], [n['lat'] for n in origins_list]), crs="EPSG:4326")
    origins_gdf["id"] = [n["id"] for n in origins_list]
    dests_gdf = gpd.GeoDataFrame(dests_list, geometry=gpd.points_from_xy([n['lng'] for n in dests_list], [n['lat'] for n in dests_list]), crs="EPSG:4326")
    dests_gdf["id"] = [n["id"] for n in dests_list]

    try:
        computer = DetailedItineraries(
            transport_network, origins=origins_gdf, destinations=dests_gdf, departure=departure_time,
            transport_modes=[TransportMode.WALK, TransportMode.TRANSIT],
            max_public_transport_rides=MAX_TRANSFERS, max_time=timedelta(minutes=MAX_TRAVEL_TIME_MIN)
        )
    except: return path_map

    if computer.empty: return path_map

    mode_col = 'transport_mode' if 'transport_mode' in computer.columns else 'mode'

    def get_val(row, candidates, default=None):
        for c in candidates:
            if c in row.index and pd.notna(row[c]): return str(row[c]).strip()
        return default

    # 3. ìƒì„¸ ê²½ë¡œ íŒŒì‹±
    for (from_id, to_id), group in computer.groupby(['from_id', 'to_id']):
        best_route, best_time = None, float("inf")
        # ê°€ì¥ ë¹ ë¥¸ ê²½ë¡œ ì„ íƒ ë¡œì§ (ê¸°ì¡´ ìœ ì§€)
        for _, opt in group.groupby("option"):
            total = sum(max(1, duration_to_minutes(get_val(leg, ['travel_time', 'duration'], 0))) for _, leg in opt.iterrows())
            if total < best_time: best_time, best_route = total, opt
        
        if best_route is None: continue

        segments = [] # ê°œë³„ ìŠ¤í…ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
        for _, leg in best_route.iterrows():
            raw_mode = str(leg[mode_col]).upper()
            dur = max(1, duration_to_minutes(get_val(leg, ['travel_time', 'duration'], 0)))

            if 'WALK' in raw_mode:
                segments.append(f"ë„ë³´ : {dur}ë¶„")
                continue

            from_stop_id = str(get_val(leg, ['start_stop_id', 'from_stop_id'])).strip()
            to_stop_id = str(get_val(leg, ['end_stop_id', 'to_stop_id'])).strip()
            from_stop = get_stop_name(from_stop_id) or "ì •ë¥˜ì¥"
            to_stop = get_stop_name(to_stop_id) or "ì •ë¥˜ì¥"
            
            current_route_id = str(get_val(leg, ['route_id'])).strip()
            current_route_name = get_route_name(current_route_id) or 'ëŒ€ì¤‘êµí†µ'
            mode_label = "ì§€í•˜ì² " if any(x in raw_mode for x in ['SUBWAY', 'RAIL', 'METRO']) else "ë²„ìŠ¤"
            
            final_route_str = ""

            # [ìˆ˜ì • ìš”ì²­ 1] ê°™ì€ êµ¬ê°„ì„ ê°€ëŠ” ë‹¤ë¥¸ ëª¨ë“  ë²„ìŠ¤ ë²ˆí˜¸ ì°¾ê¸°
            if mode_label == "ë²„ìŠ¤" and STOP_ROUTE_MAP:
                routes_at_start = STOP_ROUTE_MAP.get(from_stop_id, set())
                routes_at_end = STOP_ROUTE_MAP.get(to_stop_id, set())
                common_route_ids = routes_at_start.intersection(routes_at_end)
                
                # í˜„ì¬ íƒ‘ìŠ¹í•œ ë…¸ì„ ë„ í¬í•¨ ë³´ì¥
                if current_route_id not in common_route_ids: common_route_ids.add(current_route_id)

                bus_names = []
                for rid in common_route_ids:
                    rname = get_route_name(rid)
                    if rname:
                        bus_names.append(rname)
                
                # ë²ˆí˜¸ìˆœ ì •ë ¬ (ê¹”ë”í•œ ì¶œë ¥ì„ ìœ„í•´)
                bus_names.sort()
                
                if not bus_names:
                    final_route_str = current_route_name
                else:
                    # [ì¢…ë¡œ02, 1020, 7025] í˜•íƒœë¡œ ë‚˜ì—´
                    final_route_str = ", ".join(bus_names)
            else:
                final_route_str = current_route_name

            segments.append(f"[{mode_label}][{final_route_str}] : {from_stop} â†’ {to_stop} : {dur}ë¶„")

        # [ìˆ˜ì • ìš”ì²­ 2] ë¬¸ìì—´ joinì„ í•˜ì§€ ì•Šê³  ë¦¬ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì €ì¥
        DETAILED_PATH_CACHE[make_cache_key({"id":from_id}, {"id":to_id}, departure_time)] = segments
        path_map[(int(from_id), int(to_id))] = segments

    return path_map

# ============================================================
# 5. ë…¸ë“œ ë¹Œë” & ìµœì í™” (OR-Tools)
# ============================================================
def build_fixed_nodes(fixed_events, day_start_dt):
    nodes = []
    BUFFER = 15
    for event in fixed_events:
        event_start = parse_time(event["start"])
        event_end = parse_time(event["end"])
        orig_start_min = int((event_start - day_start_dt).total_seconds() / 60)
        orig_end_min = int((event_end - day_start_dt).total_seconds() / 60)
        
        raw_start_min = orig_start_min - BUFFER
        buffered_start_min = max(0, raw_start_min)
        final_stay = (orig_end_min - orig_start_min) + (orig_start_min - buffered_start_min) + BUFFER

        nodes.append({
            "name": event["title"], "category": "ê³ ì •ì¼ì •", "lat": None, "lng": None,
            "stay": final_stay, "type": "fixed", "window": (buffered_start_min, buffered_start_min + 10),
            "orig_time_str": f"{event['start']} - {event['end']}"
        })
    return nodes

def build_nodes(places, restaurants, fixed_events, day_start_dt):
    nodes = []
    first_place = places[0] if places else {"lat": 37.5665, "lng": 126.9780}
    nodes.append({"name": "ì‹œì‘ì ", "category": "ì¶œë°œ", "lat": first_place["lat"], "lng": first_place["lng"], "stay": 0, "type": "depot"})

    for p in places:
        nodes.append({"name": p["name"], "category": p["category"], "lat": p["lat"], "lng": p["lng"], "stay": stay_time_map.get(p["category"], 60), "type": "spot"})

    if restaurants:
        nodes.append({"name": restaurants[0]["name"], "category": "ì‹ë‹¹", "lat": restaurants[0]["lat"], "lng": restaurants[0]["lng"], "stay": 70, "type": "lunch"})
        nodes.append({"name": restaurants[1]["name"], "category": "ì‹ë‹¹", "lat": restaurants[1]["lat"], "lng": restaurants[1]["lng"], "stay": 70, "type": "dinner"})

    nodes.extend(build_fixed_nodes(fixed_events, day_start_dt))
    return nodes

def build_time_windows(nodes, day_start_dt):
    windows = []
    def get_rel(t_str): return int((parse_time(t_str) - day_start_dt).total_seconds() / 60)
    
    l_s, l_e = get_rel(LUNCH_WINDOW[0]), get_rel(LUNCH_WINDOW[1])
    d_s, d_e = get_rel(DINNER_WINDOW[0]), get_rel(DINNER_WINDOW[1])

    for n in nodes:
        if n["type"] == "lunch": windows.append((l_s, l_e))
        elif n["type"] == "dinner": windows.append((d_s, d_e))
        elif n["type"] == "fixed": windows.append(n["window"])
        else: windows.append((0, 24 * 60))
    return windows

def optimize_day(places, restaurants, fixed_events, start_time_str, target_date_str, end_time_str=None):
    TRAVEL_BUFFER = 5
    day_start_dt = datetime.strptime(start_time_str, "%H:%M")
    
    # r5py ê³„ì‚° ê¸°ì¤€ ë‚ ì§œ ì„¤ì •
    SAFE_GTFS_DATE = target_date_str
    r5_departure_dt = datetime.combine(datetime.strptime(SAFE_GTFS_DATE, "%Y-%m-%d"), datetime.strptime("11:00", "%H:%M").time())
    display_start_dt = datetime.combine(datetime.strptime(target_date_str, "%Y-%m-%d"), day_start_dt.time())

    # Horizon ê³„ì‚°
    max_horizon_minutes = 24 * 60
    if end_time_str:
        diff = int((datetime.strptime(end_time_str, "%H:%M") - day_start_dt).total_seconds() / 60)
        if diff > 0: max_horizon_minutes = diff

    nodes = build_nodes(places, restaurants, fixed_events, day_start_dt)
    for idx, node in enumerate(nodes): node["id"] = idx
    n = len(nodes)

    # ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
    r5_travel_times = get_r5py_matrix(nodes, r5_departure_dt)
    time_matrix = [[0]*n for _ in range(n)]
    
    for i in range(n):
        for j in range(n):
            if i == j: continue
            val = r5_travel_times.get((i, j))
            if val is None: val = travel_minutes(nodes[i], nodes[j])
            
            # ê³ ì •ì¼ì • ì´ë™ì‹œê°„ ë³´ì •
            if (nodes[i]["type"]=="fixed" or nodes[j]["type"]=="fixed"):
                if not (nodes[i]["type"]=="depot" and nodes[j]["type"]=="fixed"):
                    val = max(val, 20)
            
            time_matrix[i][j] = nodes[i]["stay"] + int(val)

    # OR-Tools Solver
    manager = pywrapcp.RoutingIndexManager(n, 1, 0)
    routing = pywrapcp.RoutingModel(manager)

    def time_callback(from_idx, to_idx):
        return time_matrix[manager.IndexToNode(from_idx)][manager.IndexToNode(to_idx)]

    transit_callback = routing.RegisterTransitCallback(time_callback)
    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback)
    routing.AddDimension(transit_callback, 30, max_horizon_minutes, False, "Time")
    time_dim = routing.GetDimensionOrDie("Time")

    time_windows = build_time_windows(nodes, day_start_dt)
    solver = routing.solver()

    for i, node in enumerate(nodes):
        index = manager.NodeToIndex(i)
        if node["type"] == "depot": continue
        
        window = time_windows[i]
        if node["type"] == "fixed":
            time_dim.CumulVar(index).SetRange(max(0, window[0]), min(max_horizon_minutes, window[1]))
            continue

        overlap_start, overlap_end = max(0, window[0]), min(max_horizon_minutes, window[1])
        if overlap_start > overlap_end:
            routing.AddDisjunction([index], 0)
            solver.Add(routing.VehicleVar(index) == -1)
        else:
            time_dim.CumulVar(index).SetRange(overlap_start, overlap_end)
            penalty = 1000000 if node["type"] in ["lunch", "dinner"] else 100000
            routing.AddDisjunction([index], penalty)

    search_params = pywrapcp.DefaultRoutingSearchParameters()
    search_params.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC
    search_params.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH
    search_params.time_limit.seconds = 1

    solution = routing.SolveWithParameters(search_params)
    if not solution: return []

    index = routing.Start(0)
    visited_nodes = []
    while not routing.IsEnd(index):
        node_idx = manager.IndexToNode(index)
        nodes[node_idx]['arrival_min'] = solution.Value(time_dim.CumulVar(index))
        visited_nodes.append(nodes[node_idx])
        index = solution.Value(routing.NextVar(index))

    trip_legs = [(visited_nodes[i], visited_nodes[i+1]) for i in range(len(visited_nodes)-1)]
    
    print("ğŸš€ ìƒì„¸ ê²½ë¡œ ê³„ì‚° ì¤‘...")
    start_path_time = time.time()
    path_map = get_all_detailed_paths(trip_legs, r5_departure_dt)
    end_path_time = time.time()
    print(f"â± ìƒì„¸ ê²½ë¡œ ê³„ì‚° ì™„ë£Œ: {round(end_path_time - start_path_time, 2)}ì´ˆ")

    timeline = []
    actual_visits = [n for n in visited_nodes if n["type"] != "depot"]

    # ì²« ì¥ì†Œì˜ ì‹œì‘ ì‹œê°„ ë³´ì¥
    current_time_cursor = display_start_dt + timedelta(minutes=actual_visits[0]['arrival_min'])

    for i, node in enumerate(actual_visits):
        transit_info = []
        travel_min = 0 # ì‹¤ì œ í…ìŠ¤íŠ¸ìƒ ì´ë™ ì‹œê°„
        
        # 1. ì´ë™ ì‹œê°„ ë° í…ìŠ¤íŠ¸ ê³„ì‚°
        if i > 0:
            prev = actual_visits[i-1]
            dist = haversine(prev['lat'], prev['lng'], node['lat'], node['lng'])
            
            # ìƒì„¸ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (List[str])
            r5_path_list = path_map.get((prev['id'], node['id']))
            
            # ì´ë™ ì‹œê°„ íŒŒì‹± (í…ìŠ¤íŠ¸ì—ì„œ ë¶„ ì¶”ì¶œ) ë˜ëŠ” ê±°ë¦¬ ê¸°ë°˜ ê³„ì‚°
            if r5_path_list:
                transit_info = r5_path_list
                # í…ìŠ¤íŠ¸ ë‚´ì˜ ëª¨ë“  "Xë¶„"ì„ í•©ì‚° (ì˜ˆ: "ë„ë³´ 4ë¶„", "ë²„ìŠ¤ 10ë¶„" ë“±)
                import re
                for segment in r5_path_list:
                    # "4ë¶„", "12ë¶„" ë“± ìˆ«ì ì¶”ì¶œ
                    mins = re.findall(r'(\d+)ë¶„', segment)
                    for m in mins:
                        travel_min += int(m)
            else:
                # ê²½ë¡œê°€ ì—†ìœ¼ë©´ ì§ì„ ê±°ë¦¬ ê¸°ì¤€
                travel_min = int(dist * 12)
                if dist < 0.1:
                    transit_info = ["ë„ë³´ ì´ë™ (100m ì´ë‚´)"]
                    travel_min = 0 # ê±´ë¬¼ ë‚´ ì´ë™ì€ ì‹œê°„ ê±°ì˜ ì•ˆ ì”€
                else:
                    transit_info = [f"ë„ë³´ : {travel_min}ë¶„"]

        # 2. íƒ€ì„ë¼ì¸ ì‹œê°„ í™•ì • (Logic: ì´ì „ ì¢…ë£Œ + ì´ë™ ì‹œê°„)
        if node["type"] == "fixed":
            # ê³ ì • ì¼ì •ì€ ì›ë˜ ì‹œê°„ ì—„ìˆ˜
            time_parts = node["orig_time_str"].split(" - ")
            start_dt = datetime.strptime(f"{target_date_str} {time_parts[0]}", "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(f"{target_date_str} {time_parts[1]}", "%Y-%m-%d %H:%M")
            
            # ë§Œì•½ ë„ì°©í–ˆëŠ”ë° ì‹œê°„ì´ ë‚¨ìœ¼ë©´ 'ëŒ€ê¸°' ë°œìƒ
            wait_min = int((start_dt - current_time_cursor).total_seconds() / 60)
            if wait_min > 0:
                transit_info.append(f"(ëŒ€ê¸° {wait_min}ë¶„)")
            
            current_time_cursor = end_dt # ì¢…ë£Œ ì‹œê°„ìœ¼ë¡œ ì»¤ì„œ ì´ë™
            time_str = node["orig_time_str"]
            
        else:
            start_dt = current_time_cursor + timedelta(minutes=travel_min)
            end_dt = start_dt + timedelta(minutes=node["stay"])
            
            time_str = f"{start_dt.strftime('%H:%M')} - {end_dt.strftime('%H:%M')}"
            current_time_cursor = end_dt # ë‹¤ìŒì„ ìœ„í•´ ì»¤ì„œ ì—…ë°ì´íŠ¸

        # ê²°ê³¼ ì €ì¥
        timeline.append({
            "name": node["name"], 
            "category": node["category"], 
            "time": time_str, 
            "transit_to_here": transit_info 
        })

    return timeline

# ============================================================
# 6. ë©”ì¸ ì‹¤í–‰ë¶€ (í†µí•©)
# ============================================================
if __name__ == "__main__":
    # # 1. ì—‘ì…€ ë° ê¸°ë³¸ ì •ë³´ ë¡œë“œ
    # print("ğŸ“‚ ì¥ì†Œ ë°ì´í„° ë¡œë“œ ì¤‘ (places_3000.xlsx)...")
    # try:
    #     df = pd.read_excel("places_3000.xlsx")
    # except FileNotFoundError:
    #     print("âŒ 'places_3000.xlsx' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    #     exit()

    # area = input("ì—¬í–‰í•  ì§€ì—­ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì¢…ë¡œêµ¬): ")
    
    # # 2. ì¥ì†Œ í•„í„°ë§
    # filtered_spot = df[(df["area"] == f"{area}") & (df["category"] != "ì‹ë‹¹")][["name", "lat", "lng"]]
    # filtered_restaurant = df[(df["area"] == f"{area}") & (df["category"] == "ì‹ë‹¹")][["name", "lat", "lng"]]
    # filtered_accom = df[(df["area"] == f"{area}") & (df["category"] == "ìˆ™ë°•")][["name", "lat", "lng"]]

    # places = filtered_spot.to_dict(orient="records")
    # restaurants = filtered_restaurant.to_dict(orient="records")
    # accommodations = filtered_accom.to_dict(orient="records")

    # 3. ë‚ ì§œ ì…ë ¥
    start_date = input("ì—¬í–‰ ì‹œì‘ ì¼ì (ì˜ˆ: 2026-01-20): ")
    end_date = input("ì—¬í–‰ ì¢…ë£Œ ì¼ì (ì˜ˆ: 2026-01-25): ")
    
    start = datetime.strptime(start_date, "%Y-%m-%d")
    end = datetime.strptime(end_date, "%Y-%m-%d")
    days = (end - start).days + 1
    print(f"ì´ ì—¬í–‰ ì¼ìˆ˜: {days}ì¼")

    # # 4. Gemini API í˜¸ì¶œ (1ì°¨ ê³„íš ìƒì„±)
    # schema = """
    # {
    #   "plans": {
    #     "day1": {
    #       "route": [
    #         {"name": "...", "category": "...", "lat": 0.0, "lng": 0.0}
    #       ],
    #       "restaurants": [
    #         {"name": "...", "category": "ì‹ë‹¹", "lat": 0.0, "lng": 0.0}
    #       ],
    #       "accommodations": [
    #         {"name": "...", "category": "ìˆ™ë°•", "lat": 0.0, "lng": 0.0}
    #       ]
    #     }
    #   }
    # }
    # """
    
    # system_prompt = f"""
    # ë„ˆëŠ” ì„œìš¸ ì—¬í–‰ ì¥ì†Œ ì¶”ì²œê¸°ë‹¤. ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•œë‹¤.
    # {schema}
    # ê·œì¹™:
    # - ì…ë ¥ëœ days ë§Œí¼ day1, day2, ... ìƒì„±
    # - ì—¬í–‰ ì‹œì‘ ì¼ì : {start_date}, ì—¬í–‰ ì¢…ë£Œ ì¼ì : {end_date}
    # - ë§¤ì¼ ê´€ê´‘ì§€ 5ê³³ + ì‹ë‹¹ 2ê³³ êµ¬ì„±
    # - routeì—ëŠ” places ëª©ë¡ì—ì„œë§Œ ì„ íƒ
    # - restaurantsì—ëŠ” restaurants ëª©ë¡ì—ì„œë§Œ ì„ íƒ
    # - accommodationsì—ëŠ” accommodations ëª©ë¡ì—ì„œë§Œ ì„ íƒ
    # - routeëŠ” ì´ë™ ë™ì„ ì„ ê³ ë ¤í•˜ì—¬ ë°©ë¬¸ ìˆœì„œ ìµœì í™”
    # - restaurantsëŠ” í•´ë‹¹ dayì˜ ë§ˆì§€ë§‰ ê´€ê´‘ì§€ì™€ ê°€ê¹Œìš´ ìˆœì„œë¡œ 2ê³³ ì„ íƒ
    # - accommodationsëŠ” í•´ë‹¹ dayì˜ ë§ˆì§€ë§‰ ê´€ê´‘ì§€ì™€ ê°€ê¹Œìš´ ìˆœì„œë¡œ 1ê³³ ì„ íƒ
    # - ë§ˆì§€ë§‰ ë‚ ì—ëŠ” accommodations í¬í•¨í•˜ì§€ ì•ŠìŒ
    # - ì„¤ëª… ë¬¸ì¥ì€ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤
    # - ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤
    # """

    # user_prompt = {
    #     "days": days,
    #     "start_location": {"lat": 37.5547, "lng": 126.9706},
    #     "places": places[:6 * days * 3],
    #     "restaurants": restaurants[:3 * days * 3],
    #     "accommodations": accommodations[:days * 3]
    # }

    # print("ğŸ¤– Geminiê°€ ì´ˆê¸° ê³„íšì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    # prompt = system_prompt + "\n\n" + json.dumps(user_prompt, ensure_ascii=False)
    
    # start_time = time.time()
    # response = client.models.generate_content(model="gemini-2.5-flash-lite", contents=prompt)
    # print(f"â± Gemini ì‘ë‹µ ì‹œê°„: {round(time.time() - start_time, 3)}ì´ˆ")

    # try:
    #     result = extract_json(response.text)
    #     # result.json ì €ì¥ (ë°±ì—…ìš©)
    #     with open("result.json", "w", encoding="utf-8") as f:
    #         json.dump(result, f, ensure_ascii=False, indent=2)
    # except Exception as e:
    #     print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
    #     exit()

    result = json.load(open("result.json", "r", encoding="utf-8"))

    # 5. ì„¸ë¶€ ì¼ì • ì„¤ì •
    first_day_start_str = input("ì—¬í–‰ ì²«ë‚  ì‹œì‘ ì‹œê°„ (ì˜ˆ: 14:00) : ").strip() or "10:00"
    last_day_end_str = input("ì—¬í–‰ ë§ˆì§€ë§‰ ë‚  ì¢…ë£Œ ì‹œê°„ (ì˜ˆ: 18:00) : ").strip() or "21:00"
    default_start_str = "10:00"
    default_end_str = "21:00"

    FIXED_EVENTS = []
    if input("ê³ ì • ì¼ì •ì´ ìˆë‚˜ìš”? (y/n): ").strip().lower() == "y":
        while True:
            FIXED_EVENTS.append({
                "date": input("ë‚ ì§œ (YYYY-MM-DD): "),
                "title": input("ì œëª©: "),
                "start": input("ì‹œì‘(HH:MM): "),
                "end": input("ì¢…ë£Œ(HH:MM): ")
            })
            if input("ë” ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() != "y": break

    # 6. ìµœì í™” ì‹¤í–‰ (Day loop)
    plans = result["plans"]
    current_date = start
    day_keys = list(plans.keys())

    for i, day_key in enumerate(day_keys):
        print(f"\nğŸ“… {day_key} ({current_date.strftime('%Y-%m-%d')}) ìµœì í™” ì§„í–‰...")
        
        todays_start = first_day_start_str if i == 0 else default_start_str
        todays_end = last_day_end_str if i == len(day_keys)-1 else default_end_str
        
        start_opt_time = time.time()
        timeline = optimize_day(
            places=plans[day_key]["route"],
            restaurants=plans[day_key]["restaurants"],
            fixed_events=get_fixed_events_for_day(FIXED_EVENTS, current_date.strftime("%Y-%m-%d")),
            start_time_str=todays_start,
            target_date_str=current_date.strftime("%Y-%m-%d"),
            end_time_str=todays_end
        )
        end_opt_time = time.time()
        print(f"â± {day_key} ìµœì í™” ì™„ë£Œ: {round(end_opt_time - start_opt_time, 2)}ì´ˆ")
        
        result["plans"][day_key]["timeline"] = timeline
        
        if timeline:
            for t in timeline:
                if t.get('transit_to_here'):
                    # ë§Œì•½ ë¬¸ìì—´ë¡œ ë“¤ì–´ì™”ë‹¤ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì„œ ì²˜ë¦¬ (ì•ˆì „ì¥ì¹˜)
                    infos = t['transit_to_here']
                    if isinstance(infos, str):
                        infos = [infos]
                        
                    for step in infos:
                        print(f"    â–¼ {step}")
                
                print(f"  [{t['time']}] {t['name']} ({t['category']})")

        current_date += timedelta(days=1)

    # 7. ìµœì¢… ê²°ê³¼ ì €ì¥
    with open("result_timeline.json", "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… ìµœì¢… ì¼ì •ì´ 'result_timeline.json' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")